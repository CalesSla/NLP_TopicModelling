{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5f3fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\tensorflow_hub\\__init__.py:74: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n",
      "C:\\Users\\User\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\tensorflow_hub\\__init__.py:75: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  distutils.version.LooseVersion(required_tensorflow_version)):\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import textwrap\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import PorterStemmer\n",
    "import spacy\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import os\n",
    "from gensim.models import CoherenceModel, TfidfModel\n",
    "import pyLDAvis.gensim\n",
    "import re\n",
    "from bertopic import BERTopic\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, SpectralClustering, MeanShift, Birch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from gensim.models.nmf import Nmf\n",
    "import warnings\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from top2vec import Top2Vec\n",
    "from collections import Counter\n",
    "from sklearn.metrics import silhouette_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "stops.extend(['has', 'been', 're', 'com', 'edu', 'use', 'said', 'would', 'could', 'told', 'also', 'one', 'two', 'mr', 'new', 'year', 'people'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5fc2879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset preparation\n",
    "\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space', 'talk.politics.guns']\n",
    "\n",
    "\n",
    "# remove = ('headers', 'footers', 'quotes')\n",
    "# newsgroups_train = fetch_20newsgroups(subset = 'train', categories = categories, remove = remove)\n",
    "\n",
    "# col_names = [label.split('.')[1] for label in newsgroups_train.target_names]\n",
    "\n",
    "# df = pd.DataFrame({'text': newsgroups_train['data'], 'labels': [col_names[i] for i in newsgroups_train['target']]})\n",
    "# df.to_csv('four_groups.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d87f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d4c1a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "  \n",
    "  def __init__(self, path):\n",
    "    self.path = path\n",
    "  \n",
    "  def read_file(self):\n",
    "    df = pd.read_csv(self.path)\n",
    "    return df\n",
    "  \n",
    "  def drop_missing_vals(self, df):\n",
    "    df.dropna(axis = 0, how = 'any', inplace = True)\n",
    "  \n",
    "  def mark_long_reviews_method(self, df):\n",
    "    df['Num_words_text'] = df['text'].apply(lambda x:len(str(x).split()))\n",
    "    mask = (df['Num_words_text'] < 100) & (df['Num_words_text'] >=20)\n",
    "    df = df[mask]\n",
    "    return df\n",
    "  \n",
    "  def remove_punctuation_method(self, text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "  \n",
    "  def remove_newline_characters_method(self, df):\n",
    "    df['text'] = df['text'].str.replace('\\n', ' ')\n",
    "    \n",
    "  def remove_digits_and_nonalphanumeric_characters_method(self, df):\n",
    "    df['text'] = df['text'].str.replace('[^a-zA-Z0-9\\s]', '')\n",
    "    \n",
    "  def lowercase_text_method(self, df):\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    \n",
    "  def normalize_whitespace_method(self, text):\n",
    "    return re.sub('[\\s]+', ' ', text)\n",
    "  \n",
    "  def remove_stopwords_method(self, text):\n",
    "    return \" \".join([word for word in text.split() if word not in stops])\n",
    "  \n",
    "  def lemmatization_method(self, text, allowed_postags = ['NOUN', 'ADJ']):\n",
    "    nlp = spacy.load('en_core_web_sm', disable = ['parser', 'ner'])\n",
    "    doc = nlp(''.join(text))\n",
    "    doc = [token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "    return ' '.join(doc)\n",
    "\n",
    "  def stemming_method(self, text):\n",
    "    doc = [PorterStemmer().stem(w).strip() for w in text.split()]\n",
    "    return ' '.join(doc)\n",
    "  \n",
    "  def remove_digit_words_method(self, text):\n",
    "    pattern = re.compile(r'\\b\\w*\\d\\w*\\b')\n",
    "    return pattern.sub('', text)\n",
    "  \n",
    "  def remove_short_words_method(self, text):\n",
    "    text = text.split()\n",
    "    text = [word for word in text if len(word) > 2]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "  \n",
    "  \n",
    "  \n",
    "  def __call__(self, \n",
    "               drop_missing=True, \n",
    "               mark_long_reviews=False, \n",
    "               remove_punctuation=True,\n",
    "               remove_newline_characters=True,\n",
    "               remove_digits_and_nonalphanumeric_characters=True,\n",
    "               lowercase_text=True,\n",
    "               normalize_whitespace=True,\n",
    "               remove_stopwords=True,\n",
    "               lemmatize=True,\n",
    "               stem=True,\n",
    "               remove_digit_words=False,\n",
    "               remove_short_words=False):\n",
    "    \n",
    "    df = self.read_file()\n",
    "    df = df.head(20)\n",
    "    \n",
    "    if drop_missing:\n",
    "      self.drop_missing_vals(df)\n",
    "    \n",
    "    if mark_long_reviews:\n",
    "      df = self.mark_long_reviews_method(df)\n",
    "    \n",
    "    if remove_punctuation:\n",
    "      df['text'] = df['text'].apply(self.remove_punctuation_method)\n",
    "    \n",
    "    if remove_newline_characters:\n",
    "      self.remove_newline_characters_method(df)\n",
    "    \n",
    "    if remove_digits_and_nonalphanumeric_characters:\n",
    "      self.remove_digits_and_nonalphanumeric_characters_method(df)\n",
    "      \n",
    "    if lowercase_text:\n",
    "      self.lowercase_text_method(df)\n",
    "      \n",
    "    if normalize_whitespace:\n",
    "      df['text'] = df['text'].map(self.normalize_whitespace_method)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "      df['text'] = df['text'].apply(self.remove_stopwords_method)\n",
    "    \n",
    "    if lemmatize:\n",
    "      nlp = spacy.load('en_core_web_sm', disable = ['parser', 'ner'])\n",
    "      df['text'] = df['text'].map(self.lemmatization_method)\n",
    "    \n",
    "    if stem:\n",
    "      df['text'] = df['text'].map(self.stemming_method)\n",
    "      \n",
    "    if remove_digit_words:\n",
    "      df['text'] = df['text'].apply(self.remove_digit_words_method)\n",
    "    \n",
    "    if remove_short_words:\n",
    "      df['text'] = df['text'].map(self.remove_short_words_method)\n",
    "      \n",
    "    if normalize_whitespace:\n",
    "      df['text'] = df['text'].map(self.normalize_whitespace_method)\n",
    "      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "af2ae899",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Preprocessor('four_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "87036f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first rule humor sorri second rule thing bad joke spite request post list nicknam list plot devic keeper list obviou play last name full advanc idea list ol timer nicknam altath poster good post other start poster bobbi bill second rule humor copeland'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = p()\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9f833ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello,\\nI purchased my new 486 with a NoName graphics card installed which is obviously \\nSpeedstar 24 compatible. Its name is \"VGA 4000 TrueColor\".\\nIt is accompanied with some drivers and the utilities VMODE, XMODE and\\nat least one more MODE, as well as some drivers for Lotus, Windows, etc.\\nOnly one of the drivers is told to provide the TrueColor mode, namely\\nthe Windows 3.1 driver.\\nNowhere else, except in the ad, is any pointer to the TrueColor mode.\\nSome articles in this group about the Speedstar 24 and some other facts\\nmade me believe that my card is compatible to that one.\\n\\nDoes anybody out there know how this mode can be adjusted? How can I write\\na driver which allows me to have 16.7 millions of colors with a resolution\\nof 640 x 480 with 45 Hz interlaced ?'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('four_groups.csv')\n",
    "df = df.dropna(axis = 0, how = 'any')\n",
    "\n",
    "def remove_digit_words(text):\n",
    "    pattern = re.compile(r'\\b\\w*\\d\\w*\\b')\n",
    "    return pattern.sub('', text)\n",
    "  \n",
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ec2ea399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello,\\nI purchased my new  with a NoName graphics card installed which is obviously \\nSpeedstar  compatible. Its name is \"VGA  TrueColor\".\\nIt is accompanied with some drivers and the utilities VMODE, XMODE and\\nat least one more MODE, as well as some drivers for Lotus, Windows, etc.\\nOnly one of the drivers is told to provide the TrueColor mode, namely\\nthe Windows . driver.\\nNowhere else, except in the ad, is any pointer to the TrueColor mode.\\nSome articles in this group about the Speedstar  and some other facts\\nmade me believe that my card is compatible to that one.\\n\\nDoes anybody out there know how this mode can be adjusted? How can I write\\na driver which allows me to have . millions of colors with a resolution\\nof  x  with  Hz interlaced ?'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(remove_digit_words)\n",
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "49e84c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello,\\nI purchased my new  with a NoName graphics card installed which is obviously \\nSpeedstar  compatible. Its name is \"VGA  TrueColor\".\\nIt is accompanied with some drivers and the utilities VMODE, XMODE and\\nat least one more MODE, as well as some drivers for Lotus, Windows, etc.\\nOnly one of the drivers is told to provide the TrueColor mode, namely\\nthe Windows . driver.\\nNowhere else, except in the ad, is any pointer to the TrueColor mode.\\nSome articles in this group about the Speedstar  and some other facts\\nmade me believe that my card is compatible to that one.\\n\\nDoes anybody out there know how this mode can be adjusted? How can I write\\na driver which allows me to have . millions of colors with a resolution\\nof  x  with  Hz interlaced ?'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(r'\\b\\w*\\d\\w*\\b')\n",
    "pattern.sub('', df['text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc96e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c33fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text': newsgroups_train['data'], 'labels': [col_names[i] for i in newsgroups_train['target']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd42c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('four_groups.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af3ac701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('four_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87ffa374",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[43mnan\u001b[49m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nan' is not defined"
     ]
    }
   ],
   "source": [
    "df[df['text'] is nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "203b60de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>NaN</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>NaN</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>NaN</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>NaN</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>NaN</td>\n",
       "      <td>graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>NaN</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>NaN</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>NaN</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>NaN</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text    labels\n",
       "133   NaN     space\n",
       "176   NaN  religion\n",
       "202   NaN  religion\n",
       "220   NaN   atheism\n",
       "268   NaN  politics\n",
       "332   NaN  religion\n",
       "359   NaN  religion\n",
       "366   NaN  politics\n",
       "393   NaN  graphics\n",
       "410   NaN  religion\n",
       "414   NaN  politics\n",
       "440   NaN     space\n",
       "488   NaN  graphics\n",
       "572   NaN     space\n",
       "640   NaN  religion\n",
       "678   NaN  graphics\n",
       "778   NaN  graphics\n",
       "816   NaN     space\n",
       "852   NaN  politics\n",
       "1012  NaN   atheism\n",
       "1045  NaN  religion\n",
       "1270  NaN   atheism\n",
       "1334  NaN  religion\n",
       "1366  NaN  religion\n",
       "1379  NaN  graphics\n",
       "1383  NaN  religion\n",
       "1439  NaN     space\n",
       "1444  NaN  religion\n",
       "1499  NaN     space\n",
       "1515  NaN  politics\n",
       "1525  NaN   atheism\n",
       "1621  NaN  graphics\n",
       "1639  NaN  graphics\n",
       "1643  NaN     space\n",
       "1802  NaN  graphics\n",
       "1836  NaN  politics\n",
       "1885  NaN  religion\n",
       "1974  NaN   atheism\n",
       "1979  NaN     space\n",
       "1986  NaN     space\n",
       "1995  NaN  religion\n",
       "2012  NaN  politics\n",
       "2081  NaN  politics\n",
       "2088  NaN  graphics\n",
       "2167  NaN   atheism\n",
       "2221  NaN  graphics\n",
       "2252  NaN  graphics\n",
       "2271  NaN  graphics\n",
       "2299  NaN   atheism\n",
       "2325  NaN     space\n",
       "2370  NaN   atheism\n",
       "2453  NaN     space\n",
       "2479  NaN  religion\n",
       "2489  NaN  politics\n",
       "2540  NaN     space\n",
       "2547  NaN     space"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5978f4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2033]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f215811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
