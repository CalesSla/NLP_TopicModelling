{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05845873",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_modeller' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 61\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m textwrap\u001b[38;5;241m.\u001b[39mfill(x, replace_whitespace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, fix_sentence_endings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Calculate the coherence and perplexity scores\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoherence_perp_logl\u001b[39m(sentences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vectorizer\u001b[38;5;241m=\u001b[39m\u001b[43mlda_modeller\u001b[49m\u001b[38;5;241m.\u001b[39mvectorizer):\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m sentences \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_modeller' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the sklearn LDA model with Count Vectorizer\n",
    "%run pkgs/lda_modeller.ipynb\n",
    "\n",
    "\n",
    "# Plot top words per topic\n",
    "\n",
    "def plot_top_words(model, feature_names, n_top_words = 7):\n",
    "  fig, axes = plt.subplots(1, 5, figsize = (30, 10), sharex = True)\n",
    "  axes = axes.flatten()\n",
    "  for topic_idx, topic in enumerate(model.components_):\n",
    "    top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
    "    top_features = [feature_names[i] for i in top_features_ind]\n",
    "    weights = topic[top_features_ind]\n",
    "    \n",
    "    ax = axes[topic_idx]\n",
    "    ax.barh(top_features, weights, height = 0.7)\n",
    "    ax.set_title(f'Topic {topic_idx + 1}', fontdict = {'fontsize': 30})\n",
    "    ax.invert_yaxis()\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 20)\n",
    "    for i in 'top right left'.split():\n",
    "      ax.spines[i].set_visible(False)\n",
    "    fig.suptitle(\"LDA\", fontsize = 40)\n",
    "  \n",
    "  plt.subplots_adjust(top = 0.90, bottom = 0.05, wspace = 0.90, hspace = 0.3)\n",
    "  plt.show()\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "# Estimate model accuracy:\n",
    "def est_accuracy(lda_modeller, topic_vocab):\n",
    "  \n",
    "  preds_col_name = 'preds ' + lda_modeller.lib\n",
    "  \n",
    "  if lda_modeller.lib == 'skl':\n",
    "    \n",
    "    new_sentences = lda_modeller.vectorizer.transform(df['text'])\n",
    "    topic_distributions = lda_modeller.lda_model.transform(new_sentences)\n",
    "    most_probable_topics = topic_distributions.argmax(axis=1)\n",
    "    preds = [topic_vocab[num_topic] for num_topic in most_probable_topics]\n",
    "\n",
    "    \n",
    "  elif lda_modeller.lib == 'gensim':\n",
    "    \n",
    "    new_words = [nltk.word_tokenize(sentence) for sentence in df['text']]\n",
    "    new_doc_dict = corpora.Dictionary(new_words)\n",
    "    new_doc_bow = [new_doc_dict.doc2bow(doc) for doc in new_words]\n",
    "    new_doc_topics = [lda_modeller.lda_model.get_document_topics(doc) for doc in new_doc_bow]\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    for i in new_doc_topics:\n",
    "      cur_pred = [-1, -1]\n",
    "      for prediction in i:\n",
    "        if prediction[1] > cur_pred[1]:\n",
    "          cur_pred[0] = prediction[0]\n",
    "          cur_pred[1] = prediction[1]\n",
    "      preds.append(cur_pred[0])\n",
    "    preds = [topic_vocab[num_topic] for num_topic in preds]\n",
    "  \n",
    "  df[preds_col_name] = preds\n",
    "  acc = sum(df['labels'] == df[preds_col_name]) / len(df)  \n",
    "  print(f'Supposed model accuracy: {acc}')\n",
    "  \n",
    "  \n",
    "   \n",
    "# Extract latent variables and sample a topic\n",
    "def sample_topic(lda_modeller, rand_seed=0, topic_vocab=None, num_topics=5, print_article=False):\n",
    "  Z = lda_modeller.lda_model.transform(lda_modeller.vectorized_sentences)\n",
    "  np.random.seed(rand_seed)\n",
    "  i = np.random.choice(len(df))\n",
    "  z = Z[i]\n",
    "  topics = np.arange(num_topics) + 1\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.barh(topics, z)\n",
    "  ax.set_yticks(topics)\n",
    "  ax.set_title('True label: %s' % df.iloc[i]['labels'])\n",
    "  \n",
    "  if print_article:\n",
    "    print(wrap(df.iloc[i]['text']))\n",
    "\n",
    "  \n",
    "# Text wrapper\n",
    "def wrap(x):\n",
    "  return textwrap.fill(x, replace_whitespace = False, fix_sentence_endings = True)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the coherence and perplexity scores\n",
    "def coherence_perp_logl(lda_modeller, sentences=None):\n",
    "  if sentences == None:\n",
    "    sentences = df['text']\n",
    "    \n",
    "  vocab = lda_modeller.vectorizer.get_feature_names_out()\n",
    "  words = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "  id2word = corpora.Dictionary(words)\n",
    "  \n",
    "  topics = []\n",
    "  for i in range(lda_modeller.lda_model.n_components):\n",
    "    topic_words = [vocab[j] for j in lda_modeller.lda_model.components_[i].argsort()[:-10 - 1:-1]]\n",
    "    topics.append(topic_words)\n",
    "\n",
    "  coherence_model_lda = CoherenceModel(topics=topics, texts=words, dictionary=id2word, coherence='c_v')\n",
    "  coherence_lda = coherence_model_lda.get_coherence()\n",
    "  perplexity = np.log(lda_modeller.lda_model.perplexity(lda_modeller.vectorized_sentences))\n",
    "  log_likelihood = lda_modeller.lda_model.score(lda_modeller.vectorized_sentences)\n",
    "  print(f'The coherence score is: {round(coherence_lda, 3)}')\n",
    "  print(f'The log perplexity score is: {round(perplexity, 3)}')\n",
    "  print(f'The log likelihood is: {round(log_likelihood, 3)}')\n",
    "  \n",
    "  return vocab, words, id2word\n",
    "  \n",
    "  \n",
    "\n",
    "# Print top words per topic  \n",
    "def print_n_words_per_topic(lda_modeller, num_words=15):\n",
    "  vocab = np.array(lda_modeller.vectorizer.get_feature_names_out())\n",
    "  top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_words-1:-1]]\n",
    "  topic_words = ([top_words(t) for t in H1])\n",
    "  topics = [' '.join(t) for t in topic_words]\n",
    "  for topic in topics:\n",
    "    print(topic)\n",
    "    print('\\n')\n",
    "    \n",
    "      \n",
    "    \n",
    "# Topic per document matrix\n",
    "def topic_per_doc_matrix(lda_modeller):\n",
    "  colnames = ['Topic' + str(i) for i in range(lda_modeller.lda_model.n_components)]\n",
    "  docnames = ['Doc' + str(i) for i in range(len(df['text']))]\n",
    "  df_doc_topic = pd.DataFrame(np.round(W1, 2), columns = colnames, index = docnames)\n",
    "  df_doc_topic['dominant_topic'] = np.argmax(df_doc_topic.values, axis = 1)\n",
    "  return df_doc_topic\n",
    "\n",
    "\n",
    "\n",
    "# Create document-term matrix\n",
    "def create_document_term_matrix(dataframe, column_name='text', vectorizer='count', stops=stops, min_df=2, max_df=0.95):\n",
    "  if vectorizer == 'count':\n",
    "    vectorizer = CountVectorizer(stop_words = list(stops),\n",
    "                                        min_df = min_df,\n",
    "                                        max_df = max_df)\n",
    "  elif vectorizer == 'tfidf':\n",
    "    vectorizer = TfidfVectorizer(stop_words = list(stops),\n",
    "                                 min_df = min_df,\n",
    "                                 max_df = max_df)\n",
    "  else:\n",
    "    raise ValueError('The vectorizer value can be either \"count\" or \"tfidf\"')\n",
    "  \n",
    "  data = vectorizer.fit_transform(dataframe[column_name])\n",
    "  df_dtm = pd.DataFrame(data.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "  df_dtm.index = dataframe.index\n",
    "  return df_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf9013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca6729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec1dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
