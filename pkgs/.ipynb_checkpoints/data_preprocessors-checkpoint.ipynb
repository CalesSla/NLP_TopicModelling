{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6a7681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "  \n",
    "  def __init__(self, path):\n",
    "    self.path = path\n",
    "    self.nlp = spacy.load('en_core_web_sm', disable = ['parser', 'ner'])\n",
    "  \n",
    "  # Read the data\n",
    "  def read_file(self):\n",
    "    df = pd.read_csv(self.path)\n",
    "    return df\n",
    "  \n",
    "  # Remove rows with missing values\n",
    "  def drop_missing_vals(self, df):\n",
    "    df.dropna(axis = 0, how = 'any', inplace = True)\n",
    "  \n",
    "  # Itentify long enough review\n",
    "  def mark_long_reviews_method(self, df):\n",
    "    df['Num_words_text'] = df['text'].apply(lambda x:len(str(x).split()))\n",
    "    mask = (df['Num_words_text'] < 100) & (df['Num_words_text'] >=20)\n",
    "    df = df[mask]\n",
    "    return df\n",
    "  \n",
    "  # Remove punctuation\n",
    "  def remove_punctuation_method(self, text):\n",
    "    return text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "  \n",
    "  # Remove newline characters\n",
    "  def remove_newline_characters_method(self, df):\n",
    "    df['text'] = df['text'].str.replace('\\n', ' ')\n",
    "    \n",
    "  # Remove non alphanumeric characters\n",
    "  def remove_nonalphanumeric_characters_method(self, df):\n",
    "    df['text'] = df['text'].str.replace('[^a-zA-Z0-9\\s]', ' ')\n",
    "  \n",
    "  # Lowercase the text\n",
    "  def lowercase_text_method(self, df):\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    \n",
    "  # Normalize whitespaces\n",
    "  def normalize_whitespace_method(self, text):\n",
    "    return re.sub('[\\s]+', ' ', text)\n",
    "  \n",
    "  # Remove stopwords\n",
    "  def remove_stopwords_method(self, text):\n",
    "    return \" \".join([word for word in text.split() if word not in stops])\n",
    "  \n",
    "  # Lemmatization\n",
    "  def lemmatization_method(self, text, allowed_postags = ['NOUN', 'ADJ', 'ADV', 'PRON', 'PROPN']):\n",
    "    doc = self.nlp(''.join(text))\n",
    "    doc = [token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "    return ' '.join(doc)\n",
    "  \n",
    "  # Stemming\n",
    "  def stemming_method(self, text):\n",
    "    doc = [PorterStemmer().stem(w).strip() for w in text.split()]\n",
    "    return ' '.join(doc)\n",
    "  \n",
    "  # Remove words with digits\n",
    "  def remove_digit_words_method(self, text):\n",
    "    pattern = re.compile(r'\\b\\w*\\d\\w*\\b')\n",
    "    return pattern.sub('', text)\n",
    "  \n",
    "  # Remove short words\n",
    "  def remove_short_words_method(self, text):\n",
    "    text = text.split()\n",
    "    text = [word for word in text if len(word) > 2]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "  \n",
    "  def remove_short_texts_method(self, df, length = 5):\n",
    "    df = df[df['text'].map(lambda x: len(x.split())) > length]\n",
    "    return df\n",
    "  \n",
    "  \n",
    "  \n",
    "  def __call__(self, \n",
    "               drop_missing=True, \n",
    "               mark_long_reviews=False, \n",
    "               remove_punctuation=True,\n",
    "               remove_newline_characters=True,\n",
    "               remove_nonalphanumeric_characters=True,\n",
    "               lowercase_text=True,\n",
    "               normalize_whitespace=True,\n",
    "               remove_stopwords=True,\n",
    "               lemmatize=True,\n",
    "               stem=True,\n",
    "               remove_digit_words=False,\n",
    "               remove_short_words=False,\n",
    "               remove_short_texts=True):\n",
    "    \n",
    "    df = self.read_file()\n",
    "    \n",
    "    if drop_missing:\n",
    "      self.drop_missing_vals(df)\n",
    "    \n",
    "    if mark_long_reviews:\n",
    "      df = self.mark_long_reviews_method(df)\n",
    "    \n",
    "    if remove_punctuation:\n",
    "      df['text'] = df['text'].apply(self.remove_punctuation_method)\n",
    "    \n",
    "    if remove_newline_characters:\n",
    "      self.remove_newline_characters_method(df)\n",
    "    \n",
    "    if remove_nonalphanumeric_characters:\n",
    "      self.remove_nonalphanumeric_characters_method(df)\n",
    "      \n",
    "    if lowercase_text:\n",
    "      self.lowercase_text_method(df)\n",
    "      \n",
    "    if normalize_whitespace:\n",
    "      df['text'] = df['text'].map(self.normalize_whitespace_method)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "      df['text'] = df['text'].apply(self.remove_stopwords_method)\n",
    "    \n",
    "    if lemmatize:\n",
    "      df['text'] = df['text'].map(self.lemmatization_method)\n",
    "    \n",
    "    if stem:\n",
    "      df['text'] = df['text'].map(self.stemming_method)\n",
    "      \n",
    "    if remove_digit_words:\n",
    "      df['text'] = df['text'].apply(self.remove_digit_words_method)\n",
    "    \n",
    "    if remove_short_words:\n",
    "      df['text'] = df['text'].map(self.remove_short_words_method)\n",
    "      \n",
    "    if normalize_whitespace:\n",
    "      df['text'] = df['text'].map(self.normalize_whitespace_method)\n",
    "    \n",
    "    if remove_short_texts:\n",
    "      df = self.remove_short_texts_method(df)\n",
    "    \n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac15e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
