{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f02a71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69bc37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b25330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "  with open(file, 'r', encoding = 'utf-8') as f:\n",
    "    data = json.load(f)\n",
    "  return (data)\n",
    "\n",
    "def write_data(file, data):\n",
    "  with open(file, 'w', encoding = 'utf-8') as f:\n",
    "    json.dump(data, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7105d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6cefbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('ushmm_dn.json')['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10558050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags = ['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "  nlp = spacy.load('en_core_web_sm', disable = ['parser', 'ner'])\n",
    "  texts_out = []\n",
    "  for text in texts:\n",
    "    doc = nlp(text)\n",
    "    new_text = []\n",
    "    for token in doc:\n",
    "      if token.pos_ in allowed_postags:\n",
    "        new_text.append(token.lemma_)\n",
    "    final = \" \".join(new_text)\n",
    "    texts_out.append(final)\n",
    "  return (texts_out)\n",
    "\n",
    "lemmatized_texts = lemmatization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0a1f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_words(texts):\n",
    "  final = []\n",
    "  for text in texts:\n",
    "    new = gensim.utils.simple_preprocess(text, deacc = True)\n",
    "    final.append(new)\n",
    "  return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98295c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "corpus = []\n",
    "for text in data_words:\n",
    "  new = id2word.doc2bow(text)\n",
    "  corpus.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14f260e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus, id2word = id2word, num_topics = 30, random_state = 100, update_every = 1, chunksize = 100, passes = 10, alpha = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faa6ac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "C:\\Users\\User\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\sklearn\\manifold\\_mds.py:299: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds = 'mmds', R = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f377cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
