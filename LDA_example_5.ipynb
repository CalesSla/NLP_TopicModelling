{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe8ef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d4ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/srivatsan88/YouTubeLI/blob/master/dataset/consumer_compliants.zip?raw=true', compression = 'zip', sep = ',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e45a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_df = df[['Consumer complaint narrative', 'Product', 'Company']].rename(columns = {'Consumer complaint narrative': 'complaints'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aabbb71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_hold = train_test_split(complaints_df, test_size = 0.6, random_state = 111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c42ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Debt collection                8720\n",
       "Credit card or prepaid card    5297\n",
       "Mortgage                       3809\n",
       "Checking or savings account    2822\n",
       "Student loan                   1236\n",
       "Vehicle loan or lease          1097\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca2027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(text):\n",
    "  tokens = [word for word in nltk.word_tokenize(text) if len(word) > 3 and (len(word.strip('Xx/')) > 2)]\n",
    "  tokens = [stemmer.stem(item) for item in tokens]\n",
    "  return tokens\n",
    "\n",
    "vectorizer_tf = TfidfVectorizer(tokenizer = tokenize, stop_words = 'english', max_df = 0.75, min_df = 50, max_features = 10000, use_idf = False, norm = None)\n",
    "tf_vectors = vectorizer_tf.fit_transform(X_train.complaints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b156ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectors.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6f2d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = decomposition.LatentDirichletAllocation(n_components = 6, max_iter = 3, learning_method = 'online', learning_offset = 50, n_jobs = -1, random_state = 111)\n",
    "\n",
    "W1 = lda.fit_transform(tf_vectors)\n",
    "H1 = lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f011751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00114034, 0.11071407, 0.23730026, 0.00114375, 0.49695421,\n",
       "        0.15274736],\n",
       "       [0.32157986, 0.07933833, 0.00117156, 0.00116331, 0.00116719,\n",
       "        0.59557976],\n",
       "       [0.00522585, 0.00526942, 0.10523552, 0.00526173, 0.00529843,\n",
       "        0.87370906],\n",
       "       ...,\n",
       "       [0.00304667, 0.27103466, 0.15027818, 0.00306514, 0.00305656,\n",
       "        0.56951879],\n",
       "       [0.01859061, 0.01865304, 0.37339021, 0.01872748, 0.01857241,\n",
       "        0.55206625],\n",
       "       [0.00133922, 0.00133128, 0.00133334, 0.21368028, 0.78098801,\n",
       "        0.00132788]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d537cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 15\n",
    "\n",
    "vocab = np.array(vectorizer_tf.get_feature_names_out())\n",
    "\n",
    "top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_words-1:-1]]\n",
    "topic_words = ([top_words(t) for t in H1])\n",
    "topics = [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e82c92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['citi offer state provid applic requir purchas thi document term contract consum servic complaint sale',\n",
       " 'thi told receiv said phone time ask number inform contact email becaus sent need compani',\n",
       " 'credit thi charg account card disput report balanc payment receiv statement capit late inform issu',\n",
       " 'thi debt report collect credit account compani inform letter agenc provid valid request receiv state',\n",
       " 'payment loan mortgag thi month paid time make year servic insur receiv compani home late',\n",
       " 'account bank card check thi close money open credit chase charg fund transact deposit fraud']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8b58865",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['Topic' + str(i) for i in range(lda.n_components)]\n",
    "docnames = ['Doc' + str(i) for i in range(len(X_train.complaints))]\n",
    "df_doc_topic = pd.DataFrame(np.round(W1, 2), columns = colnames, index = docnames)\n",
    "df_doc_topic['dominant_topic'] = np.argmax(df_doc_topic.values, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92717117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc22976</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc22977</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc22978</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc22979</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc22980</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22981 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  dominant_topic\n",
       "Doc0        0.00    0.11    0.24    0.00    0.50    0.15               4\n",
       "Doc1        0.32    0.08    0.00    0.00    0.00    0.60               5\n",
       "Doc2        0.01    0.01    0.11    0.01    0.01    0.87               5\n",
       "Doc3        0.04    0.51    0.02    0.43    0.00    0.00               1\n",
       "Doc4        0.00    0.00    0.20    0.64    0.00    0.15               3\n",
       "...          ...     ...     ...     ...     ...     ...             ...\n",
       "Doc22976    0.36    0.22    0.18    0.00    0.00    0.23               0\n",
       "Doc22977    0.17    0.00    0.00    0.17    0.16    0.49               5\n",
       "Doc22978    0.00    0.27    0.15    0.00    0.00    0.57               5\n",
       "Doc22979    0.02    0.02    0.37    0.02    0.02    0.55               5\n",
       "Doc22980    0.00    0.00    0.00    0.21    0.78    0.00               4\n",
       "\n",
       "[22981 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63ab45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHold = lda.transform(vectorizer_tf.transform(X_hold.complaints[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dbc2d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['Topic' + str(i) for i in range(lda.n_components)]\n",
    "docnames = ['Doc' + str(i) for i in range(len(X_hold.complaints[:5]))]\n",
    "df_doc_topic = pd.DataFrame(np.round(WHold, 2), columns = colnames, index = docnames)\n",
    "df_doc_topic['dominant_topic'] = np.argmax(df_doc_topic.values, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cd4b8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.64</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  dominant_topic\n",
       "Doc0    0.01    0.04    0.04    0.00    0.00    0.91               5\n",
       "Doc1    0.00    0.00    0.00    0.50    0.49    0.00               3\n",
       "Doc2    0.01    0.01    0.33    0.01    0.01    0.64               5\n",
       "Doc3    0.03    0.12    0.00    0.01    0.84    0.00               4\n",
       "Doc4    0.00    0.12    0.43    0.00    0.35    0.10               2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59153f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab12d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
