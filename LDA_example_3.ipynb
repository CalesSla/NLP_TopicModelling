{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d76125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# libraries for visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f69a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK      dll pa                     0   \n",
      "\n",
      "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
      "0                       1      5  1303862400  Good Quality Dog Food   \n",
      "1                       0      1  1346976000      Not as Advertised   \n",
      "\n",
      "                                                Text  \n",
      "0  I have bought several of the Vitality canned d...  \n",
      "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "568454\n",
      "Unique Products\n",
      "74258\n",
      "Unique Users\n",
      "256059\n"
     ]
    }
   ],
   "source": [
    "review_data= pd.read_csv(\"Reviews.csv\")\n",
    "print(review_data.head(2))\n",
    "print(len(review_data))\n",
    "print('Unique Products')\n",
    "print(len(review_data.groupby('ProductId')))\n",
    "print('Unique Users')\n",
    "print(len(review_data.groupby('UserId')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd59619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text ): \n",
    "    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n",
    "    delete_dict[' '] = ' ' \n",
    "    table = str.maketrans(delete_dict)\n",
    "    text1 = text.translate(table)\n",
    "    #print('cleaned:'+text1)\n",
    "    textArr= text1.split()\n",
    "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>3))]) \n",
    "    \n",
    "    return text2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64ae5e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') # run this one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e9adfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset --------\n",
      "5    363111\n",
      "4     80655\n",
      "1     52264\n",
      "3     42638\n",
      "2     29743\n",
      "Name: Score, dtype: int64\n",
      "568411\n",
      "-------------------------\n",
      "No of Short reviews\n",
      "373281\n"
     ]
    }
   ],
   "source": [
    "review_data.dropna(axis = 0, how ='any',inplace=True) \n",
    "\n",
    "review_data['Text'] = review_data['Text'].apply(clean_text)\n",
    "review_data['Num_words_text'] = review_data['Text'].apply(lambda x:len(str(x).split())) \n",
    "\n",
    "print('-------Dataset --------')\n",
    "print(review_data['Score'].value_counts())\n",
    "print(len(review_data))\n",
    "print('-------------------------')\n",
    "max_review_data_sentence_length  = review_data['Num_words_text'].max()\n",
    "\n",
    "mask = (review_data['Num_words_text'] < 100) & (review_data['Num_words_text'] >=20)\n",
    "df_short_reviews = review_data[mask]\n",
    "df_sampled = df_short_reviews.groupby('Score').apply(lambda x: x.sample(n=20000)).reset_index(drop = True)\n",
    "\n",
    "print('No of Short reviews')\n",
    "print(len(df_short_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adea2346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    textArr = text.split(' ')\n",
    "    rem_text = \" \".join([i for i in textArr if i not in stop_words])\n",
    "    return rem_text\n",
    "\n",
    "# remove stopwords from the text\n",
    "df_sampled['Text']=df_sampled['Text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1e9aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']): \n",
    "    output = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(sent) \n",
    "        output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1042e032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drinking year last boxes different much weaker kcups coffee still weak favorite anymore find favorite\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m text_list\u001b[38;5;241m=\u001b[39mdf_sampled[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(text_list[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m tokenized_reviews \u001b[38;5;241m=\u001b[39m \u001b[43mlemmatization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenized_reviews[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mlemmatization\u001b[1;34m(texts, allowed_postags)\u001b[0m\n\u001b[0;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[1;32m----> 6\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      7\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend([token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;129;01min\u001b[39;00m allowed_postags ])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\spacy\\language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\spacy\\pipeline\\tok2vec.py:125\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    123\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m--> 125\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 44\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     46\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 44\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     46\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\spacy\\ml\\staticvectors.py:56\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, docs, is_train)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE896)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     vectors_data \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE896)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text_list=df_sampled['Text'].tolist()\n",
    "print(text_list[1])\n",
    "tokenized_reviews = lemmatization(text_list)\n",
    "print(tokenized_reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2292e9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45428"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5585178",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokenized_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfd65c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=10, random_state=100,\n",
    "                chunksize=1000, passes=50,iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f171297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.033*\"time\" + 0.019*\"great\" + 0.015*\"small\" + 0.015*\"minute\" + 0.015*\"bottle\" + 0.015*\"little\" + 0.014*\"work\" + 0.012*\"pasta\" + 0.011*\"size\" + 0.011*\"large\"'),\n",
       " (1,\n",
       "  '0.064*\"flavor\" + 0.034*\"good\" + 0.032*\"taste\" + 0.015*\"great\" + 0.014*\"love\" + 0.014*\"green\" + 0.012*\"nice\" + 0.012*\"favorite\" + 0.011*\"brand\" + 0.011*\"drink\"'),\n",
       " (2,\n",
       "  '0.074*\"chip\" + 0.043*\"butter\" + 0.041*\"peanut\" + 0.030*\"blend\" + 0.024*\"popcorn\" + 0.023*\"potato\" + 0.020*\"yummy\" + 0.017*\"bag\" + 0.017*\"snack\" + 0.016*\"flavorful\"'),\n",
       " (3,\n",
       "  '0.041*\"salt\" + 0.035*\"flavor\" + 0.024*\"protein\" + 0.022*\"spicy\" + 0.016*\"diet\" + 0.015*\"pepper\" + 0.015*\"heat\" + 0.014*\"taste\" + 0.013*\"syrup\" + 0.012*\"great\"'),\n",
       " (4,\n",
       "  '0.045*\"product\" + 0.044*\"price\" + 0.043*\"store\" + 0.039*\"amazon\" + 0.029*\"great\" + 0.029*\"good\" + 0.021*\"order\" + 0.020*\"time\" + 0.015*\"year\" + 0.014*\"grocery\"'),\n",
       " (5,\n",
       "  '0.062*\"sauce\" + 0.036*\"cheese\" + 0.032*\"soup\" + 0.020*\"noodle\" + 0.016*\"cook\" + 0.015*\"local\" + 0.015*\"tomato\" + 0.015*\"dish\" + 0.014*\"combination\" + 0.013*\"restaurant\"'),\n",
       " (6,\n",
       "  '0.046*\"chocolate\" + 0.045*\"good\" + 0.029*\"cookie\" + 0.029*\"snack\" + 0.025*\"great\" + 0.021*\"sweet\" + 0.021*\"flavor\" + 0.021*\"taste\" + 0.018*\"candy\" + 0.016*\"texture\"'),\n",
       " (7,\n",
       "  '0.066*\"water\" + 0.065*\"sugar\" + 0.036*\"milk\" + 0.031*\"calorie\" + 0.025*\"coconut\" + 0.024*\"taste\" + 0.023*\"drink\" + 0.020*\"energy\" + 0.019*\"almond\" + 0.018*\"product\"'),\n",
       " (8,\n",
       "  '0.186*\"coffee\" + 0.029*\"good\" + 0.024*\"bean\" + 0.024*\"strong\" + 0.017*\"flavor\" + 0.016*\"roast\" + 0.016*\"vanilla\" + 0.015*\"cup\" + 0.015*\"kcup\" + 0.015*\"bold\"'),\n",
       " (9,\n",
       "  '0.072*\"food\" + 0.025*\"treat\" + 0.019*\"dog\" + 0.019*\"good\" + 0.019*\"product\" + 0.013*\"healthy\" + 0.013*\"great\" + 0.012*\"chicken\" + 0.012*\"cat\" + 0.012*\"ingredient\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4fd7b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\newtensorflow\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el168015918847566884177429128\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el168015918847566884177429128_data = {\"mdsDat\": {\"x\": [-0.1141326025029516, -0.1780757679391297, -0.12486647479203156, -0.07688130215074042, -0.06978822574045411, -0.0744686559065737, 0.09631914952719733, 0.051990190365510586, 0.07522149205730964, 0.41468219708186405], \"y\": [-0.08942160325704268, 0.15475913170176447, 0.08479020566072434, -0.046006860580511025, 0.18792226078041468, -0.04711835694593995, -0.25181565554927443, -0.19898901590300117, 0.04938816738681297, 0.15649172670605302], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [16.613830987581995, 16.040415761430598, 15.597185161916837, 11.08343631042944, 10.135822170098518, 8.277793308035257, 6.881308485258937, 5.825599068456044, 5.445477265126496, 4.099131481665882]}, \"tinfo\": {\"Term\": [\"coffee\", \"food\", \"flavor\", \"store\", \"sugar\", \"water\", \"price\", \"chip\", \"amazon\", \"chocolate\", \"sauce\", \"taste\", \"snack\", \"treat\", \"time\", \"cookie\", \"product\", \"salt\", \"butter\", \"milk\", \"peanut\", \"sweet\", \"strong\", \"calorie\", \"order\", \"dog\", \"drink\", \"bean\", \"blend\", \"cheese\", \"green\", \"smooth\", \"tea\", \"juice\", \"ginger\", \"apple\", \"cherry\", \"lemon\", \"olive\", \"allergy\", \"soda\", \"chai\", \"cinnamon\", \"banana\", \"blueberry\", \"stash\", \"coat\", \"beverage\", \"evening\", \"orange\", \"mother\", \"garlic\", \"italian\", \"pumpkin\", \"iced\", \"maple\", \"kick\", \"onion\", \"unique\", \"traditional\", \"mild\", \"flavor\", \"honey\", \"rich\", \"black\", \"taste\", \"light\", \"nice\", \"drink\", \"good\", \"favorite\", \"breakfast\", \"brand\", \"love\", \"strong\", \"wonderful\", \"different\", \"fruit\", \"great\", \"sweet\", \"organic\", \"little\", \"many\", \"well\", \"variety\", \"much\", \"product\", \"store\", \"amazon\", \"grocery\", \"item\", \"shipping\", \"hair\", \"bulk\", \"service\", \"customer\", \"shipment\", \"seller\", \"complaint\", \"condition\", \"online\", \"summer\", \"dollar\", \"stevia\", \"convenience\", \"smoothie\", \"hooked\", \"ship\", \"freezer\", \"muffin\", \"fancy\", \"shake\", \"vendor\", \"everyday\", \"business\", \"shampoo\", \"sister\", \"order\", \"price\", \"deal\", \"cost\", \"save\", \"purchase\", \"thank\", \"subscribe\", \"area\", \"product\", \"cheap\", \"can\", \"box\", \"gift\", \"available\", \"month\", \"year\", \"excellent\", \"time\", \"happy\", \"case\", \"great\", \"good\", \"perfect\", \"bag\", \"quality\", \"last\", \"pack\", \"love\", \"package\", \"fresh\", \"brand\", \"food\", \"treat\", \"dog\", \"chicken\", \"cat\", \"rice\", \"meal\", \"baby\", \"meat\", \"grain\", \"beef\", \"pill\", \"formula\", \"bone\", \"fish\", \"vegetable\", \"training\", \"pleasant\", \"puppy\", \"moist\", \"wellness\", \"balance\", \"biscuit\", \"feed\", \"chew\", \"supply\", \"newman\", \"jerky\", \"tuna\", \"salmon\", \"picky\", \"ingredient\", \"quick\", \"health\", \"healthy\", \"tooth\", \"diet\", \"month\", \"product\", \"year\", \"organic\", \"good\", \"easy\", \"problem\", \"stuff\", \"great\", \"little\", \"perfect\", \"love\", \"small\", \"brand\", \"time\", \"happy\", \"chocolate\", \"cookie\", \"candy\", \"bar\", \"cereal\", \"bread\", \"crunchy\", \"cake\", \"flour\", \"nuts\", \"chewy\", \"crunch\", \"pancake\", \"pretzel\", \"glutenfree\", \"strawberry\", \"brownie\", \"surprise\", \"egg\", \"beautiful\", \"crisp\", \"baking\", \"nut\", \"waffle\", \"birthday\", \"raisin\", \"lovely\", \"mix\", \"dairy\", \"mustard\", \"texture\", \"snack\", \"wheat\", \"sweet\", \"tasty\", \"soft\", \"good\", \"fruit\", \"delicious\", \"taste\", \"great\", \"flavor\", \"free\", \"love\", \"little\", \"favorite\", \"whole\", \"healthy\", \"nice\", \"thing\", \"recipe\", \"dark\", \"minute\", \"pasta\", \"delivery\", \"plastic\", \"wife\", \"lunch\", \"salad\", \"granola\", \"pod\", \"medium\", \"carb\", \"cooking\", \"fast\", \"sandwich\", \"pleased\", \"liquid\", \"afternoon\", \"door\", \"heavy\", \"eater\", \"mess\", \"room\", \"girl\", \"craving\", \"ball\", \"style\", \"jar\", \"peppermint\", \"purse\", \"winter\", \"hour\", \"open\", \"bottle\", \"night\", \"work\", \"time\", \"container\", \"small\", \"large\", \"size\", \"little\", \"great\", \"first\", \"piece\", \"long\", \"thing\", \"good\", \"package\", \"product\", \"coffee\", \"bean\", \"roast\", \"cup\", \"kcup\", \"bold\", \"keurig\", \"awesome\", \"machine\", \"starbuck\", \"maker\", \"french\", \"seed\", \"brew\", \"decaf\", \"instant\", \"espresso\", \"latte\", \"skeptical\", \"cappuccino\", \"brewing\", \"mini\", \"bonus\", \"town\", \"magic\", \"mocha\", \"goodness\", \"golden\", \"fuel\", \"comparable\", \"vanilla\", \"ground\", \"strong\", \"dark\", \"weak\", \"morning\", \"bitter\", \"good\", \"perfect\", \"flavor\", \"taste\", \"aroma\", \"great\", \"favorite\", \"full\", \"sugar\", \"coconut\", \"energy\", \"almond\", \"cracker\", \"fiber\", \"oatmeal\", \"cocoa\", \"creamy\", \"reasonable\", \"drinking\", \"refreshing\", \"pricey\", \"wine\", \"gram\", \"satisfied\", \"fridge\", \"adult\", \"creamer\", \"herb\", \"travel\", \"oats\", \"trick\", \"enjoy\", \"sugary\", \"filler\", \"celiac\", \"baked\", \"joe\", \"farm\", \"water\", \"milk\", \"calorie\", \"drinker\", \"substitute\", \"packet\", \"drink\", \"kid\", \"sweet\", \"taste\", \"powder\", \"free\", \"product\", \"bottle\", \"breakfast\", \"alternative\", \"healthy\", \"natural\", \"cream\", \"spicy\", \"pepper\", \"heat\", \"sweetener\", \"chili\", \"sodium\", \"warm\", \"subtle\", \"berry\", \"blood\", \"pocket\", \"brewer\", \"spoon\", \"fabulous\", \"lime\", \"diabetic\", \"costco\", \"splenda\", \"nutritious\", \"terrific\", \"touch\", \"grape\", \"member\", \"flavour\", \"vegetarian\", \"antioxidant\", \"season\", \"dressing\", \"beer\", \"tangy\", \"salt\", \"protein\", \"syrup\", \"diet\", \"vinegar\", \"flavor\", \"salty\", \"artificial\", \"high\", \"calorie\", \"amazing\", \"taste\", \"great\", \"stuff\", \"good\", \"much\", \"powder\", \"little\", \"amount\", \"chip\", \"butter\", \"peanut\", \"blend\", \"popcorn\", \"potato\", \"yummy\", \"flavorful\", \"skin\", \"date\", \"old\", \"prime\", \"movie\", \"young\", \"kettle\", \"finger\", \"addictive\", \"jelly\", \"greasy\", \"share\", \"flake\", \"bill\", \"crust\", \"expiration\", \"cube\", \"freshness\", \"tortilla\", \"dental\", \"medicine\", \"memory\", \"supermarket\", \"bag\", \"single\", \"salty\", \"snack\", \"kid\", \"corn\", \"salt\", \"great\", \"easy\", \"good\", \"delicious\", \"taste\", \"love\", \"healthy\", \"fresh\", \"sauce\", \"cheese\", \"soup\", \"noodle\", \"cook\", \"tomato\", \"combination\", \"restaurant\", \"sour\", \"yogurt\", \"plant\", \"pizza\", \"earth\", \"tart\", \"start\", \"tree\", \"pantry\", \"find\", \"steep\", \"flower\", \"staple\", \"base\", \"interesting\", \"pour\", \"enjoyable\", \"preference\", \"carrot\", \"asian\", \"temperature\", \"german\", \"office\", \"dish\", \"dinner\", \"veggie\", \"local\", \"homemade\", \"recipe\", \"fresh\", \"family\"], \"Freq\": [30798.0, 22329.0, 32586.0, 13896.0, 8893.0, 9500.0, 14981.0, 8068.0, 12464.0, 10299.0, 5061.0, 23250.0, 8283.0, 7939.0, 17224.0, 6486.0, 27731.0, 5823.0, 4722.0, 6096.0, 4440.0, 9750.0, 7005.0, 5414.0, 6978.0, 6023.0, 7276.0, 4035.0, 3288.0, 2936.0, 4528.188708289366, 3384.596488534265, 2860.8203265263787, 2387.236213396599, 1905.8857517954605, 1746.391964214846, 1547.677149446238, 1543.610786901324, 1534.4625159755103, 1431.6160949211935, 1406.2799212115212, 1327.665281313949, 1279.8231816633897, 1180.4873668174366, 1048.3761683553598, 1040.3202941278344, 1019.8618670923609, 971.4233025920878, 938.4551339830178, 924.1984864034871, 903.4973561412455, 893.6835087644732, 889.021145725509, 887.5193421172708, 875.3522950233073, 835.6589407329653, 832.9909852685593, 771.9665248658824, 767.4036113315091, 748.7776865292676, 1692.5839777853812, 21125.158803322647, 2132.5685533890073, 2351.586700401493, 2452.5171899883762, 10703.400519302908, 2557.5279727900775, 4131.498332968377, 3549.2340985842407, 11268.013666207626, 3913.2660305236864, 1843.1393832000656, 3780.9073304929857, 4721.59686653596, 3027.713466818998, 2503.5703090517577, 2616.460278751038, 2202.1256265003612, 4990.259432314112, 2754.2364615220986, 2274.3419097111264, 3063.810928244121, 2181.4371886262543, 2183.2049906370444, 1890.2504322511188, 1980.0764752872549, 2195.7706096754773, 13895.424433812565, 12463.18626970461, 4596.517001411497, 3671.1614022561243, 3538.886490987161, 1754.7836429301667, 1419.2916256577398, 1384.8916603703435, 1121.1761776164176, 1014.2423011267815, 1008.6487276098102, 988.5251185351079, 969.68230994738, 950.4676126703298, 910.5955709543364, 772.9603665557966, 767.1731897448662, 763.5128097521349, 658.8063051612338, 651.7862243169872, 641.0872325587812, 573.7346192369173, 566.0697295832463, 547.7412287810527, 528.8807112081189, 519.172152356677, 502.5128541726806, 495.026287275101, 492.3694538047609, 480.6036264504535, 6796.139443379112, 14165.428324908056, 2650.985470263546, 1974.0571944060632, 1152.8849749241822, 2678.0980013351073, 2567.8775762999326, 1274.7082971776251, 1030.256977304995, 14571.140727644568, 2834.8447874006383, 1554.0659696487899, 1948.5295054282376, 1788.93179690894, 2274.4943875457616, 3283.6914959252995, 4957.431499850907, 2766.153651266604, 6520.013772790194, 3114.115932425101, 2314.9928192321363, 9399.75180906651, 9164.63088275365, 3094.0929731523916, 2608.181433313413, 2628.205289243602, 2121.154152685012, 2410.2402599150646, 3501.147672134631, 2151.973017445092, 2212.80166303357, 2237.128428761489, 22328.856845410843, 7938.400949246084, 6022.786692623015, 3856.4328473717314, 3778.0089008541927, 3451.6321878099366, 3102.4357350026667, 2663.396892300472, 2095.2830519290746, 1843.2171870822551, 1534.2626895472815, 1393.2654466326196, 1353.2087660594273, 1275.7854482305381, 1181.498427289233, 1052.5449843539916, 1041.2480957105656, 1018.6529379455637, 985.1297698302142, 902.9928456858935, 896.6183061855561, 883.8072509816124, 823.9416534909582, 823.6331529527645, 783.6675112807394, 699.1536943887804, 684.0886816493097, 671.5675995136494, 667.3094056742891, 666.1730541864533, 1573.8504434898798, 3704.9795723205953, 1791.5367351710222, 2113.3407233279104, 3972.765305147286, 1582.9386397497556, 2182.0052705776043, 2627.3132278435096, 5800.73838061427, 3426.2880621074496, 2303.1598111884973, 5919.684446811847, 2003.0521442073516, 1894.57606024124, 2151.7812272709607, 3966.2084698743797, 2906.9234099372306, 2072.297073534081, 2469.5460816738996, 2102.3785643075316, 2190.5029128161805, 2251.0803284351164, 1868.3910053750562, 10298.97792675407, 6485.5940577888805, 3953.337752219922, 3539.4288625305308, 3449.9497338581973, 2835.152332883547, 2072.0580150189285, 1969.1734044837112, 1524.9839989849843, 1158.6037391608415, 1154.7458244169675, 1008.50172584311, 986.1993211373638, 927.793645490131, 902.151177341079, 887.2473859325831, 734.965647170446, 713.9811043238228, 696.2726034237252, 690.8789988409579, 654.6281170452016, 644.7054562373953, 627.4164510319255, 579.156065784528, 570.108331012557, 546.4347820406903, 540.782871370511, 527.65046184349, 526.7102235548911, 511.4705774394963, 3593.9549387333673, 6447.265833313328, 1495.693234863774, 4642.492404327443, 2347.186680054237, 1543.2744243126697, 10026.148872578911, 2033.3875853170377, 2285.5461633914706, 4558.307853438825, 5524.521935011968, 4615.598419176818, 2122.2052273629624, 2830.3265576730278, 2721.034427914908, 2196.1128823716704, 1747.685873348972, 1976.2899101532144, 1805.4851002049313, 1549.335814411045, 1287.7756795344521, 1321.6447034987914, 3098.3222406585587, 2422.5681955744526, 1806.692279362351, 1742.7690660093892, 1729.6305681570095, 1689.1561153746989, 1639.9450129049944, 1406.313621153776, 1354.1340521918946, 1304.1449253726103, 1260.8394044994625, 1250.9948798673822, 1143.8827690266025, 1063.2976151059406, 1022.5375058534904, 989.632619018258, 951.1478461783735, 928.9642840827404, 854.0303122444018, 800.1755215369751, 734.3767491818066, 732.6507230789274, 732.3319682310081, 705.910066789578, 692.0975613155055, 656.1755283483088, 655.6902900766355, 613.879767685145, 558.6441938681713, 557.4450505008767, 1859.947521994103, 1765.8231012758474, 3035.9796282964053, 1421.013267027427, 2828.0810212623715, 6715.935648324016, 1454.6160055368184, 3121.3711766029055, 2201.5318461431666, 2293.74609857118, 2973.7014184838836, 3787.213650412353, 1629.2018743985846, 1339.0342983962662, 1479.2611237339809, 1676.4982758472813, 2158.8248345948928, 1414.5030380330843, 1719.0793152530207, 30797.09745893531, 4034.991723281622, 2709.8085866920014, 2551.9127723874676, 2462.1742857844674, 2452.108260847765, 2131.547451701427, 1977.4298093652128, 1927.4148022702404, 1815.2548431963353, 1764.093659498114, 1759.688799932028, 1726.1609363302452, 1611.685641905597, 1568.4730410219677, 1531.723358433687, 1488.6810413570806, 684.9854313441058, 603.8254156869746, 576.4913556411359, 568.1294027152927, 553.2738372209145, 531.6577038146997, 526.4615026979516, 524.4448195404586, 506.12199655602717, 503.3552702983526, 435.02522946917946, 409.8842675303649, 397.65815239850696, 2648.7963922119598, 1170.4658762282243, 3976.9098293140987, 2240.3987532169554, 915.1581612667225, 2159.0760501998084, 1606.8701885946787, 4801.597083092271, 1796.659974863501, 2781.553596777006, 2416.2979155645294, 867.2467915830558, 2213.057559451846, 1444.7610840069594, 1058.3579740246726, 8892.43232408636, 3433.413291520151, 2700.162700770348, 2625.4177941495395, 2332.6215194868864, 1576.5230180647823, 1545.4043101580187, 1509.059167207321, 1293.5741517428012, 1167.2969110136007, 1157.2475538690671, 895.3972728028274, 867.0293640475821, 816.5372906666366, 793.5873157099713, 772.2753058294508, 736.2812332438151, 719.0507689661628, 615.5517505442484, 514.9794190654061, 513.9911521411127, 498.09499246040207, 494.0455983893233, 485.7783272450869, 470.8965916670745, 447.9794414048782, 423.787898024219, 415.2730312353754, 364.2003069602796, 360.9482260000652, 9035.32642528313, 4929.246414842833, 4219.4049601078705, 1022.4495481637359, 857.4995602701892, 1514.552302893815, 3168.028714054142, 1763.5469718813551, 2353.2385049284667, 3250.277653562053, 1090.3998071402118, 1555.3578858698638, 2481.2017296716185, 1285.5546685753661, 1024.940442410221, 938.6927242536592, 1201.7234762168832, 1034.6336644419134, 889.9719021594069, 2583.30106045649, 1794.6499490356332, 1726.820129522618, 1397.896452881421, 1286.9572574143926, 1203.4536695569936, 1073.7002423406054, 920.7754902701475, 920.7571453005495, 895.5024723458263, 879.7806705751283, 752.4135548330513, 740.586259847879, 738.9647382155973, 735.211075205536, 729.4698595721599, 644.1429554169007, 618.8554460520982, 562.0343993748228, 554.1366185875747, 534.5694832338831, 525.9504412011072, 501.5046294354954, 473.1225733647695, 467.619625235936, 460.7517679489616, 455.5568850492361, 455.40144128317456, 453.55657778729545, 451.30535693230235, 4756.0503853180235, 2767.7335691868793, 1558.589268350549, 1854.7641348559896, 811.4183584682477, 4063.3330440838063, 878.2940767369909, 772.0566209928603, 1367.4024457544847, 1194.5281362717913, 919.6998671710527, 1628.5566567471424, 1444.0012692854814, 984.680788890573, 1246.2923215217904, 938.0274687505428, 820.2592769380556, 955.8312074703869, 805.3607735218923, 8067.235272684763, 4721.581849684115, 4439.910949547719, 3287.7067263324107, 2607.242562074058, 2465.1028526991095, 2186.5881910873586, 1791.6796999402143, 1308.9594700932093, 1187.8541128894133, 822.295464098303, 762.0028966472416, 724.9523030988535, 644.1760459363984, 624.0667701694506, 605.4106060822892, 590.5074598190297, 584.6013081465791, 554.3088355618451, 529.8203879191861, 520.9483501773162, 516.9476509337958, 497.95329669030957, 495.99036309619555, 462.3265922699461, 454.1297172344024, 422.90514164230586, 388.46339647579794, 365.20148426957905, 364.65409412681475, 805.3112764275594, 1838.6492697342107, 893.3195063478591, 891.8428542791537, 1835.631838330434, 1112.3803790645823, 849.9954498861275, 1066.843830446036, 1501.8850318812758, 927.4058880355226, 1620.257167290616, 697.4462718516274, 693.0545687775046, 665.1786388759484, 650.1251689653456, 633.5783048990905, 5060.470207743634, 2935.458435063326, 2660.713182833801, 1679.8804812174335, 1273.2608411554759, 1222.7031710319845, 1154.5364733810727, 1104.7281707061877, 997.0862837515784, 794.4064868986478, 735.8543928249127, 731.1097992898465, 712.7520153564848, 701.0735387970641, 685.3534732889572, 657.9872401023551, 653.2791563665381, 601.2909207931767, 596.9545801388364, 581.1251761838148, 549.3278525395907, 532.1247101025682, 515.2188781123605, 512.9676059827151, 498.67409595698746, 482.22333799173106, 457.76688997709016, 434.6394215692201, 413.35333023310653, 393.2245918951593, 835.3120507013822, 1217.997225945496, 769.4369158058561, 675.5540293055398, 1231.086829159998, 631.2408715094914, 869.1865756959861, 713.2419951936889, 596.1232565927521], \"Total\": [30798.0, 22329.0, 32586.0, 13896.0, 8893.0, 9500.0, 14981.0, 8068.0, 12464.0, 10299.0, 5061.0, 23250.0, 8283.0, 7939.0, 17224.0, 6486.0, 27731.0, 5823.0, 4722.0, 6096.0, 4440.0, 9750.0, 7005.0, 5414.0, 6978.0, 6023.0, 7276.0, 4035.0, 3288.0, 2936.0, 4529.144482024691, 3385.55238387167, 2861.7760505628353, 2388.1919663302037, 1906.841502515503, 1747.3477654479684, 1548.6329545211395, 1544.5665506974099, 1535.4183638957784, 1432.5721087062307, 1407.2356811916636, 1328.6210225311825, 1280.7789859999043, 1181.4432423297424, 1049.3319491765826, 1041.2760442923366, 1020.8179355984433, 972.3790968570139, 939.4111052760311, 925.1542544593867, 904.4533444709855, 894.6393779630929, 889.9771031221187, 888.4751310067568, 876.3081035244717, 836.6147905222656, 833.946912170394, 772.9224149374267, 768.3594598638539, 749.7335986487734, 1874.4464106267433, 32586.276145362568, 2622.7620061641337, 3069.172956582981, 3378.623859230451, 23250.316284698354, 3594.7092021851518, 8049.618339932207, 7276.752689795982, 47082.46286879686, 9052.337903498279, 2868.930695619223, 9604.389300856687, 15178.01979575451, 7005.466816133262, 5248.706567976027, 5953.422999490189, 4236.370215628123, 33378.81640443156, 9750.719373391164, 5607.394152791091, 14442.386940014841, 7433.199220157915, 8337.48854452291, 4190.792413794135, 7438.306899636299, 27731.72044877774, 13896.382079956085, 12464.143888603727, 4597.474604360466, 3672.119025973654, 3539.8440547688956, 1755.7411818235257, 1420.2492476765515, 1385.8492660469815, 1122.1337732151358, 1015.1998811662313, 1009.6063114462496, 989.4827901008917, 970.6399196507276, 951.4252278212346, 911.553300860914, 773.9179690702535, 768.1309816310885, 764.4704577641131, 659.76403413104, 652.7440554242813, 642.0448078926485, 574.6923787798547, 567.0274604763811, 548.6989229023432, 529.838517119234, 520.1297589356553, 503.4706450490101, 495.9839663659238, 493.3269552362156, 481.56142655190104, 6978.999719689071, 14981.37916929437, 2792.813941495519, 2080.35479398407, 1216.8138743114162, 3104.141850200636, 3100.513127975678, 1427.1665762660896, 1139.857856093551, 27731.72044877774, 3970.6869010488417, 1936.8167887720685, 2581.6900667370023, 2363.7545113854153, 3348.4449782129736, 5911.864421006003, 10786.749991932782, 4673.852464552218, 17224.027166380136, 5649.624122320961, 3643.500620436971, 33378.81640443156, 47082.46286879686, 6963.797713170046, 5421.770445400323, 5857.779327205865, 3798.5909075622662, 5170.419305201615, 15178.01979575451, 5167.50265889326, 6056.652458870444, 9604.389300856687, 22329.821217262754, 7939.365329461654, 6023.7510042013155, 3857.39723509028, 3778.973194412354, 3452.5966344355134, 3103.4001843032834, 2664.3612539142414, 2096.2474407140235, 1844.181606325628, 1535.2270599881597, 1394.2297763487372, 1354.1730919459017, 1276.7497633299, 1182.4628422621547, 1053.5094236056711, 1042.2124264945821, 1019.617568960775, 986.0940787819659, 903.9573635711581, 897.5825895196648, 884.7718607454465, 824.9061074967929, 824.5974769226724, 784.631871294132, 700.1182390520992, 685.0530840467961, 672.5319388029203, 668.2737692106167, 667.1374076916013, 1615.5659582094565, 5251.105373218927, 2230.4835658059037, 3007.377949755599, 7969.478408492057, 2184.4844394726465, 4037.6213264574967, 5911.864421006003, 27731.72044877774, 10786.749991932782, 5607.394152791091, 47082.46286879686, 4945.1681276348945, 4585.467945773795, 6508.446818538332, 33378.81640443156, 14442.386940014841, 6963.797713170046, 15178.01979575451, 7915.485104604504, 9604.389300856687, 17224.027166380136, 5649.624122320961, 10299.941446496188, 6486.5575398807005, 3954.3012625959454, 3540.3923532660074, 3450.9132479534223, 2836.115881376262, 2073.021572309691, 1970.136918993219, 1525.9475079791982, 1159.56730186412, 1155.7093396395119, 1009.4653042295605, 987.1628792516733, 928.7571490693693, 903.114682875758, 888.2109330730677, 735.9291490421784, 714.9447915261536, 697.2362869711502, 691.8427737720073, 655.5917113548221, 645.6690707879795, 628.3799828700373, 580.1195895711214, 571.0718793418439, 547.3982862209155, 541.7466729376807, 528.6140861066665, 527.6738061519135, 512.4341553596387, 3891.4050832588478, 8283.755104701539, 1913.6830959626477, 9750.719373391164, 4692.1427712797185, 2616.4884858752507, 47082.46286879686, 4236.370215628123, 5237.387763109175, 23250.316284698354, 33378.81640443156, 32586.276145362568, 6880.467583463381, 15178.01979575451, 14442.386940014841, 9052.337903498279, 5353.163738661511, 7969.478408492057, 8049.618339932207, 8046.692311734189, 2671.4570274414127, 3562.8947393417484, 3099.274646613384, 2423.5205776918483, 1807.6447548226834, 1743.7214388085517, 1730.5830487737474, 1690.1085941443498, 1640.8974868363448, 1407.2660836705775, 1355.0864422610907, 1305.097403327909, 1261.7918944533883, 1251.9473462087576, 1144.8352572648669, 1064.2500856369438, 1023.490020416347, 990.5850550810483, 952.1003397123642, 929.9167651950302, 854.9827494207839, 801.1280614667852, 735.329138101164, 733.603148719911, 733.2844750703936, 706.8626451306419, 693.049905179611, 657.1280159125265, 656.6426820110312, 614.8322126745371, 559.5967298836428, 558.3975362351686, 2209.994769064986, 2088.4083866716337, 4322.381679411446, 1869.289478408071, 4853.822930948239, 17224.027166380136, 2223.3246842385997, 7915.485104604504, 4703.276098971306, 5271.702146883252, 14442.386940014841, 33378.81640443156, 5437.258116700735, 2925.2975374674993, 4103.517872343172, 8046.692311734189, 47082.46286879686, 5167.50265889326, 27731.72044877774, 30798.04746794876, 4035.941815677891, 2710.7585952594104, 2552.8628636595054, 2463.1242807563003, 2453.058275192962, 2132.4974495566707, 1978.3801943240005, 1928.364878068024, 1816.2048521037398, 1765.0437293669245, 1760.6388416532818, 1727.111187034803, 1612.6356659668381, 1569.4230730399363, 1532.673502175585, 1489.6310321932651, 685.9354796409806, 604.7757377144042, 577.4413559066526, 569.0794405490601, 554.2241278676378, 532.608144813598, 527.4118221075579, 525.3949150695954, 507.07204473881006, 504.3056832320758, 435.97544986291547, 410.83432800680066, 398.6084470659445, 3548.2272144095095, 1425.9089073601012, 7005.466816133262, 3562.8947393417484, 1186.6525606664693, 4310.077237200496, 2913.021027336395, 47082.46286879686, 6963.797713170046, 32586.276145362568, 23250.316284698354, 1689.5330037799463, 33378.81640443156, 9052.337903498279, 3698.2636446267024, 8893.389645986188, 3434.3705964026794, 2701.1200224786116, 2626.3751364043383, 2333.578844615031, 1577.4803645089744, 1546.3616131521449, 1510.016456066274, 1294.531541988921, 1168.2543715688012, 1158.2049300406966, 896.3545930647034, 867.986792866329, 817.4946649530217, 794.5446208079197, 773.2327479719427, 737.2387239193299, 720.0081639468682, 616.5091153113955, 515.9368821195669, 514.9485541826625, 499.05228361896303, 495.00309821478993, 486.7357661755097, 471.8539154049861, 448.9369436474262, 424.74531712004375, 416.23057407921743, 365.15761981000594, 361.9055782423645, 9500.640260076607, 6096.974409476148, 5414.777950396147, 1247.6344589347395, 1056.4986971890626, 2407.1717036697323, 7276.752689795982, 3601.4505919373523, 9750.719373391164, 23250.316284698354, 2404.228067073009, 6880.467583463381, 27731.72044877774, 4322.381679411446, 2868.930695619223, 1960.9926759524337, 7969.478408492057, 4683.504655258308, 2700.8716397901953, 2584.2508895211367, 1795.5997379318915, 1727.7699779116065, 1398.8462710827534, 1287.9070466268936, 1204.4034594413495, 1074.6501492767632, 921.7253226733834, 921.7069683970184, 896.4523015450583, 880.7305075105328, 753.3634629889004, 741.5361695276365, 739.9147214624223, 736.1608620863469, 730.4197117492043, 645.0928554776177, 619.8052559088054, 562.9843125565804, 555.0865173568492, 535.5193848418716, 526.9002737699377, 502.4545408469064, 474.072395317481, 468.5695034275635, 461.70164692970275, 456.5067781422014, 456.35127909231977, 454.50636224867895, 452.2551940145648, 5823.737881649132, 3946.7964049664024, 2548.0964518438072, 4037.6213264574967, 1234.7171485673587, 32586.276145362568, 1770.9806148726948, 1387.5797252432099, 5430.368724866559, 5414.777950396147, 3061.965052210136, 23250.316284698354, 33378.81640443156, 6508.446818538332, 47082.46286879686, 7438.306899636299, 2404.228067073009, 14442.386940014841, 3907.7553075471637, 8068.19141532015, 4722.538033181718, 4440.867101380048, 3288.663036750334, 2608.198688230807, 2466.059034571469, 2187.544483025869, 1792.6360237326114, 1309.915697812671, 1188.810316505531, 823.25172034538, 762.9592413029487, 725.9084525786186, 645.1322968246089, 625.022891717823, 606.3668606714025, 591.4637532622405, 585.5574928843063, 555.2650162843812, 530.7766539735507, 521.9045854456529, 517.9039474227118, 498.90952412179536, 496.9465097417346, 463.2828347865946, 455.08598046776257, 423.8612906636659, 389.41961740442713, 366.1577717801186, 365.61038305149503, 1283.9344650411979, 5421.770445400323, 1697.2704642698063, 1770.9806148726948, 8283.755104701539, 3601.4505919373523, 2206.581673183791, 5823.737881649132, 33378.81640443156, 4945.1681276348945, 47082.46286879686, 5237.387763109175, 23250.316284698354, 15178.01979575451, 7969.478408492057, 6056.652458870444, 5061.4240763040225, 2936.412343607877, 2661.6670656235488, 1680.8343335370648, 1274.2148136925932, 1223.6570452465173, 1155.4905100968965, 1105.6821191969507, 998.0402084329274, 795.360480150975, 736.8082734817971, 732.0637032595033, 713.7059860999328, 702.0275166128126, 686.3074677247633, 658.9411717693125, 654.233127236548, 602.2449339138285, 597.9085776157368, 582.0790713208089, 550.281862946629, 533.0786485158897, 516.1728503857333, 513.9216465672471, 499.62812815648056, 483.17735212494637, 458.72080219732874, 435.5933255219462, 414.3073662310147, 394.17857095030854, 982.826451658851, 1690.3236566095782, 1218.108373201269, 1192.111035637426, 5938.033314168973, 1010.8136172415765, 2671.4570274414127, 6056.652458870444, 4009.8378194288907], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.296, -4.5871, -4.7552, -4.9362, -5.1614, -5.2488, -5.3696, -5.3722, -5.3782, -5.4475, -5.4654, -5.5229, -5.5596, -5.6404, -5.7591, -5.7668, -5.7867, -5.8353, -5.8699, -5.8852, -5.9078, -5.9187, -5.924, -5.9257, -5.9395, -5.9859, -5.9891, -6.0651, -6.0711, -6.0956, -5.2801, -2.7559, -5.049, -4.9512, -4.9092, -3.4358, -4.8673, -4.3877, -4.5396, -3.3844, -4.442, -5.1949, -4.4764, -4.2542, -4.6985, -4.8886, -4.8445, -5.0169, -4.1988, -4.7932, -4.9846, -4.6867, -5.0264, -5.0255, -5.1696, -5.1232, -5.0198, -3.1397, -3.2484, -4.2459, -4.4707, -4.5074, -5.2089, -5.4211, -5.4456, -5.6568, -5.7571, -5.7626, -5.7828, -5.802, -5.822, -5.8649, -6.0287, -6.0363, -6.041, -6.1885, -6.1992, -6.2158, -6.3268, -6.3402, -6.3732, -6.4082, -6.4267, -6.4593, -6.4744, -6.4797, -6.5039, -3.8549, -3.1204, -4.7963, -5.0911, -5.6289, -4.7861, -4.8281, -5.5285, -5.7414, -3.0922, -4.7292, -5.3303, -5.1041, -5.1896, -4.9495, -4.5822, -4.1703, -4.7538, -3.8963, -4.6353, -4.9318, -3.5305, -3.5559, -4.6417, -4.8126, -4.8049, -5.0193, -4.8915, -4.5181, -5.0048, -4.977, -4.966, -2.6373, -3.6715, -3.9476, -4.3934, -4.414, -4.5043, -4.611, -4.7636, -5.0035, -5.1317, -5.3151, -5.4115, -5.4407, -5.4996, -5.5764, -5.692, -5.7028, -5.7247, -5.7582, -5.8452, -5.8523, -5.8667, -5.9368, -5.9372, -5.987, -6.1011, -6.1229, -6.1413, -6.1477, -6.1494, -5.2897, -4.4335, -5.1601, -4.9949, -4.3637, -5.2839, -4.9629, -4.7772, -3.9852, -4.5117, -4.9089, -3.9649, -5.0485, -5.1042, -4.9769, -4.3654, -4.6761, -5.0145, -4.8392, -5.0001, -4.9591, -4.9318, -5.1181, -3.0695, -3.532, -4.027, -4.1376, -4.1632, -4.3595, -4.673, -4.7239, -4.9796, -5.2543, -5.2577, -5.3931, -5.4154, -5.4765, -5.5045, -5.5212, -5.7095, -5.7385, -5.7636, -5.7713, -5.8252, -5.8405, -5.8677, -5.9477, -5.9635, -6.0059, -6.0163, -6.0409, -6.0427, -6.072, -4.1223, -3.5379, -4.999, -3.8663, -4.5483, -4.9676, -3.0964, -4.6918, -4.5749, -3.8846, -3.6924, -3.8721, -4.6491, -4.3612, -4.4005, -4.6149, -4.8433, -4.7203, -4.8107, -4.9637, -5.1486, -5.1227, -4.1813, -4.4273, -4.7207, -4.7567, -4.7643, -4.7879, -4.8175, -4.9712, -5.009, -5.0466, -5.0804, -5.0882, -5.1777, -5.2508, -5.2899, -5.3226, -5.3623, -5.3859, -5.47, -5.5351, -5.6209, -5.6233, -5.6237, -5.6604, -5.6802, -5.7335, -5.7342, -5.8001, -5.8944, -5.8966, -4.6916, -4.7436, -4.2016, -4.9608, -4.2726, -3.4077, -4.9374, -4.1739, -4.523, -4.482, -4.2224, -3.9805, -4.8241, -5.0202, -4.9206, -4.7955, -4.5426, -4.9654, -4.7704, -1.6823, -3.7147, -4.1128, -4.1728, -4.2086, -4.2127, -4.3528, -4.4279, -4.4535, -4.5135, -4.542, -4.5445, -4.5638, -4.6324, -4.6596, -4.6833, -4.7118, -5.488, -5.6141, -5.6605, -5.6751, -5.7016, -5.7414, -5.7513, -5.7551, -5.7907, -5.7961, -5.942, -6.0016, -6.0318, -4.1356, -4.9523, -3.7292, -4.303, -5.1983, -4.34, -4.6354, -3.5407, -4.5237, -4.0867, -4.2274, -5.2521, -4.3153, -4.7417, -5.053, -2.7397, -3.6914, -3.9316, -3.9597, -4.0779, -4.4697, -4.4896, -4.5134, -4.6675, -4.7702, -4.7789, -5.0354, -5.0676, -5.1276, -5.1561, -5.1833, -5.2311, -5.2547, -5.4101, -5.5885, -5.5905, -5.6219, -5.63, -5.6469, -5.678, -5.7279, -5.7834, -5.8037, -5.935, -5.9439, -2.7238, -3.3297, -3.4852, -4.9027, -5.0786, -4.5098, -3.7718, -4.3576, -4.0691, -3.7462, -4.8384, -4.4832, -4.0162, -4.6737, -4.9003, -4.9882, -4.7412, -4.8909, -5.0415, -3.8093, -4.1736, -4.2121, -4.4234, -4.5061, -4.5732, -4.6873, -4.8409, -4.8409, -4.8687, -4.8864, -5.0428, -5.0587, -5.0609, -5.066, -5.0738, -5.1982, -5.2382, -5.3346, -5.3487, -5.3847, -5.4009, -5.4485, -5.5068, -5.5185, -5.5333, -5.5446, -5.5449, -5.549, -5.554, -3.1989, -3.7403, -4.3146, -4.1406, -4.9673, -3.3564, -4.8881, -5.0171, -4.4454, -4.5806, -4.8421, -4.2707, -4.3909, -4.7738, -4.5382, -4.8223, -4.9565, -4.8035, -4.9748, -2.6031, -3.1387, -3.2003, -3.5007, -3.7326, -3.7887, -3.9085, -4.1077, -4.4217, -4.5187, -4.8865, -4.9627, -5.0125, -5.1307, -5.1624, -5.1927, -5.2177, -5.2277, -5.2809, -5.3261, -5.343, -5.3507, -5.3881, -5.3921, -5.4624, -5.4803, -5.5515, -5.6364, -5.6982, -5.6997, -4.9074, -4.0819, -4.8037, -4.8054, -4.0835, -4.5844, -4.8534, -4.6262, -4.2842, -4.7662, -4.2083, -5.0512, -5.0575, -5.0986, -5.1215, -5.1473, -2.7854, -3.33, -3.4283, -3.8882, -4.1653, -4.2058, -4.2632, -4.3073, -4.4098, -4.637, -4.7136, -4.7201, -4.7455, -4.762, -4.7847, -4.8254, -4.8326, -4.9156, -4.9228, -4.9497, -5.0059, -5.0378, -5.07, -5.0744, -5.1027, -5.1362, -5.1883, -5.2401, -5.2903, -5.3402, -4.5868, -4.2097, -4.669, -4.7991, -4.199, -4.8669, -4.5471, -4.7448, -4.9242], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7947, 1.7947, 1.7946, 1.7945, 1.7944, 1.7944, 1.7943, 1.7943, 1.7943, 1.7943, 1.7943, 1.7942, 1.7942, 1.7941, 1.794, 1.794, 1.794, 1.794, 1.7939, 1.7939, 1.7939, 1.7939, 1.7939, 1.7939, 1.7938, 1.7938, 1.7938, 1.7937, 1.7937, 1.7937, 1.6929, 1.3615, 1.588, 1.5286, 1.4746, 1.0192, 1.4545, 1.128, 1.077, 0.365, 0.9563, 1.3525, 0.8627, 0.6272, 0.9561, 1.0547, 0.9728, 1.1407, -0.1055, 0.5307, 0.8925, 0.2444, 0.569, 0.455, 0.9988, 0.4714, -0.7411, 1.83, 1.83, 1.8299, 1.8298, 1.8298, 1.8295, 1.8294, 1.8294, 1.8292, 1.8291, 1.8291, 1.8291, 1.8291, 1.8291, 1.829, 1.8288, 1.8288, 1.8288, 1.8286, 1.8286, 1.8286, 1.8284, 1.8284, 1.8283, 1.8282, 1.8282, 1.8282, 1.8281, 1.8281, 1.8281, 1.8035, 1.7741, 1.7779, 1.7776, 1.7761, 1.6824, 1.6416, 1.7171, 1.729, 1.1865, 1.4931, 1.6099, 1.5487, 1.5514, 1.4433, 1.2421, 1.0526, 1.3055, 0.8586, 1.2344, 1.3765, 0.5628, 0.1935, 1.0188, 1.0983, 1.0286, 1.2474, 1.0668, 0.3633, 0.9541, 0.8232, 0.373, 1.858, 1.858, 1.8579, 1.8578, 1.8578, 1.8578, 1.8578, 1.8577, 1.8576, 1.8576, 1.8575, 1.8574, 1.8574, 1.8573, 1.8573, 1.8572, 1.8572, 1.8571, 1.8571, 1.857, 1.857, 1.857, 1.8569, 1.8569, 1.8568, 1.8567, 1.8567, 1.8566, 1.8566, 1.8566, 1.8319, 1.5093, 1.6389, 1.5053, 1.1619, 1.536, 1.2427, 1.0471, 0.2935, 0.7112, 0.9683, -0.2155, 0.9543, 0.9742, 0.7513, -0.272, 0.255, 0.646, 0.0423, 0.5323, 0.38, -0.1768, 0.7516, 2.1996, 2.1996, 2.1995, 2.1994, 2.1994, 2.1994, 2.1993, 2.1992, 2.1991, 2.1989, 2.1989, 2.1988, 2.1987, 2.1987, 2.1987, 2.1986, 2.1984, 2.1984, 2.1983, 2.1983, 2.1982, 2.1982, 2.1982, 2.1981, 2.198, 2.198, 2.1979, 2.1979, 2.1979, 2.1978, 2.1202, 1.9491, 1.9533, 1.4576, 1.507, 1.6718, 0.653, 1.4657, 1.3705, 0.5704, 0.401, 0.2453, 1.0235, 0.5203, 0.5306, 0.7834, 1.0803, 0.8053, 0.7049, 0.5523, 1.47, 1.208, 2.2888, 2.2887, 2.2886, 2.2885, 2.2885, 2.2885, 2.2885, 2.2884, 2.2884, 2.2884, 2.2883, 2.2883, 2.2883, 2.2882, 2.2882, 2.2881, 2.2881, 2.2881, 2.288, 2.2879, 2.2878, 2.2878, 2.2878, 2.2877, 2.2877, 2.2876, 2.2876, 2.2875, 2.2874, 2.2874, 2.1167, 2.1213, 1.9358, 2.0149, 1.7489, 1.3473, 1.8648, 1.3585, 1.53, 1.4569, 0.7087, 0.1128, 1.0839, 1.5076, 1.2688, 0.7205, -0.7932, 0.9935, -0.4917, 2.4916, 2.4914, 2.4912, 2.4912, 2.4912, 2.4912, 2.4911, 2.4911, 2.4911, 2.4911, 2.4911, 2.4911, 2.491, 2.491, 2.491, 2.491, 2.491, 2.4902, 2.49, 2.4899, 2.4899, 2.4899, 2.4898, 2.4898, 2.4898, 2.4897, 2.4897, 2.4894, 2.4893, 2.4892, 2.1993, 2.2942, 1.9254, 2.0277, 2.2318, 1.8003, 1.8967, 0.2086, 1.1368, 0.0307, 0.2275, 1.8247, -0.222, 0.6565, 1.2404, 2.6763, 2.6761, 2.676, 2.676, 2.676, 2.6758, 2.6757, 2.6757, 2.6756, 2.6755, 2.6755, 2.6753, 2.6753, 2.6752, 2.6752, 2.6751, 2.6751, 2.675, 2.6748, 2.6745, 2.6745, 2.6744, 2.6744, 2.6744, 2.6743, 2.6742, 2.6741, 2.6741, 2.6737, 2.6737, 2.6261, 2.4638, 2.4269, 2.4773, 2.4677, 2.213, 1.8448, 1.9624, 1.2548, 0.7088, 1.8857, 1.1894, 0.2625, 1.4637, 1.6471, 1.9396, 0.7845, 1.1664, 1.5662, 2.8425, 2.8424, 2.8424, 2.8422, 2.8422, 2.8421, 2.842, 2.8419, 2.8419, 2.8418, 2.8418, 2.8416, 2.8416, 2.8416, 2.8416, 2.8416, 2.8414, 2.8414, 2.8412, 2.8412, 2.8411, 2.8411, 2.841, 2.8409, 2.8409, 2.8408, 2.8408, 2.8408, 2.8408, 2.8408, 2.6404, 2.488, 2.3513, 2.065, 2.4231, 0.761, 2.1416, 2.2566, 1.4638, 1.3315, 1.6401, 0.1843, -0.2976, 0.9544, -0.7888, 0.7723, 1.7675, 0.1276, 1.2635, 2.9103, 2.9102, 2.9102, 2.9101, 2.91, 2.91, 2.9099, 2.9099, 2.9097, 2.9096, 2.9092, 2.9091, 2.9091, 2.9089, 2.9089, 2.9088, 2.9088, 2.9088, 2.9087, 2.9086, 2.9086, 2.9085, 2.9085, 2.9085, 2.9083, 2.9083, 2.9081, 2.9079, 2.9078, 2.9078, 2.4439, 1.829, 2.2686, 2.2244, 1.4035, 1.7356, 1.9564, 1.2131, -0.1908, 1.2366, -0.4589, 0.8942, -0.6026, -0.2172, 0.4042, 0.6529, 3.1942, 3.1941, 3.194, 3.1938, 3.1936, 3.1936, 3.1936, 3.1935, 3.1934, 3.1932, 3.1931, 3.1931, 3.1931, 3.193, 3.193, 3.1929, 3.1929, 3.1928, 3.1928, 3.1928, 3.1927, 3.1926, 3.1925, 3.1925, 3.1925, 3.1924, 3.1923, 3.1922, 3.1921, 3.192, 3.0318, 2.8667, 2.735, 2.6264, 1.6209, 2.7236, 2.0716, 1.0553, 1.2883]}, \"token.table\": {\"Topic\": [9, 7, 5, 1, 7, 1, 3, 7, 3, 4, 5, 8, 2, 1, 3, 5, 6, 7, 8, 9, 8, 1, 2, 10, 1, 6, 1, 8, 10, 1, 2, 3, 4, 6, 8, 6, 3, 1, 2, 9, 7, 4, 3, 5, 1, 4, 10, 6, 4, 3, 8, 8, 1, 9, 4, 3, 1, 6, 1, 6, 9, 8, 1, 6, 3, 6, 5, 7, 1, 2, 4, 6, 1, 2, 3, 6, 7, 9, 4, 1, 7, 6, 8, 6, 4, 2, 2, 9, 4, 7, 8, 2, 3, 4, 6, 5, 10, 1, 2, 3, 4, 9, 3, 7, 4, 1, 1, 2, 3, 4, 10, 1, 3, 4, 3, 8, 9, 4, 1, 1, 7, 7, 6, 10, 6, 2, 2, 2, 5, 2, 10, 4, 5, 3, 8, 9, 2, 6, 8, 7, 5, 1, 6, 7, 7, 7, 4, 4, 4, 9, 9, 6, 2, 4, 4, 6, 9, 2, 6, 6, 1, 4, 5, 9, 5, 9, 8, 3, 8, 1, 2, 3, 4, 6, 3, 10, 3, 10, 3, 2, 5, 8, 1, 6, 7, 7, 8, 7, 10, 1, 2, 3, 9, 5, 4, 7, 7, 10, 6, 1, 2, 2, 3, 5, 8, 9, 9, 8, 1, 2, 3, 5, 8, 9, 10, 2, 7, 5, 1, 2, 3, 4, 6, 3, 7, 7, 10, 9, 1, 2, 3, 4, 5, 6, 8, 3, 9, 1, 4, 6, 8, 9, 8, 4, 10, 3, 3, 2, 3, 4, 7, 2, 6, 1, 2, 4, 6, 9, 10, 9, 7, 1, 4, 6, 1, 2, 3, 5, 6, 7, 9, 1, 10, 2, 4, 1, 5, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 3, 7, 5, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 6, 2, 1, 2, 3, 6, 1, 3, 8, 3, 4, 7, 8, 9, 8, 5, 7, 1, 2, 3, 4, 7, 8, 5, 10, 1, 4, 2, 3, 5, 1, 1, 3, 4, 7, 8, 6, 10, 1, 2, 5, 9, 3, 7, 1, 6, 9, 6, 1, 3, 7, 9, 10, 2, 3, 5, 6, 9, 2, 3, 5, 6, 1, 1, 5, 8, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 6, 7, 9, 10, 1, 2, 3, 5, 1, 2, 3, 4, 6, 8, 9, 4, 5, 6, 6, 6, 1, 2, 3, 4, 6, 9, 1, 3, 3, 9, 5, 8, 9, 5, 1, 8, 4, 7, 6, 5, 4, 6, 3, 2, 3, 1, 3, 5, 6, 1, 9, 1, 2, 3, 5, 6, 7, 8, 9, 2, 4, 1, 3, 7, 8, 3, 1, 2, 4, 5, 8, 3, 5, 10, 4, 8, 4, 7, 7, 8, 10, 9, 1, 1, 2, 5, 9, 1, 2, 6, 1, 3, 6, 7, 1, 2, 4, 6, 8, 9, 2, 3, 4, 5, 9, 5, 7, 4, 10, 5, 9, 8, 5, 2, 3, 6, 3, 6, 3, 4, 5, 3, 10, 10, 5, 3, 5, 8, 5, 9, 9, 10, 1, 5, 7, 8, 10, 4, 2, 6, 7, 9, 2, 3, 5, 6, 9, 1, 2, 3, 4, 5, 7, 8, 3, 8, 1, 3, 1, 2, 5, 1, 2, 3, 4, 6, 3, 6, 4, 7, 3, 4, 7, 10, 7, 10, 3, 1, 4, 6, 5, 5, 3, 8, 9, 8, 9, 5, 7, 10, 2, 6, 8, 6, 2, 2, 2, 2, 9, 2, 2, 2, 1, 7, 9, 10, 2, 2, 3, 4, 5, 6, 9, 6, 9, 2, 3, 4, 5, 6, 9, 1, 2, 4, 9, 1, 8, 2, 3, 4, 10, 10, 8, 8, 8, 10, 6, 10, 1, 10, 2, 2, 4, 1, 6, 1, 2, 3, 4, 5, 6, 7, 8, 5, 2, 6, 7, 8, 8, 7, 7, 2, 4, 9, 3, 4, 1, 4, 7, 8, 1, 8, 8, 10, 1, 4, 6, 7, 8, 9, 3, 4, 8, 9, 10, 1, 10, 8, 4, 8, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 10, 3, 4, 9, 9, 8, 6, 1, 3, 7, 3, 10, 7, 3, 1, 1, 6, 1, 2, 3, 4, 6, 8, 3, 8, 3, 10, 2, 8, 9, 4, 8, 6, 7, 1, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 3, 4, 1, 2, 3, 4, 5, 5, 7, 5, 1, 3, 4, 5, 9, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 6, 10, 9, 9], \"Freq\": [0.9992159227684153, 0.9985997881727594, 0.9988443027835736, 0.9996006422973379, 0.9994764127998025, 0.262112146721994, 0.25905247185753494, 0.47883911628784515, 0.10908027828695097, 0.32495472124406055, 0.2651891795479167, 0.3004606467784278, 0.9999082256580195, 0.1023605544665164, 0.08675056991037265, 0.2763734970595943, 0.0424796301036043, 0.19781177150654294, 0.20600061586386426, 0.08777417545503781, 0.9984803023026478, 0.9992286793306867, 0.9036214423524273, 0.09562595846253842, 0.48593309403438645, 0.5131595524090293, 0.443217776111715, 0.5563644278995837, 0.9986378911540132, 0.1400650161646974, 0.6791212084403452, 0.038525345597539375, 0.030760547260050817, 0.0952681026791865, 0.016126888854783923, 0.9993023614328731, 0.9994890880835917, 0.17964611556476243, 0.4810236852083167, 0.33918809704681535, 0.997043527900516, 0.9989637558646521, 0.9991276160785718, 0.9984850944040763, 0.9987784073935737, 0.9996067234568725, 0.9979765677749566, 0.9997666428999961, 0.9987818420543553, 0.999200730614943, 0.9988859072375275, 0.999232979220882, 0.9985817292232304, 0.9982546041071705, 0.9981230395321177, 0.9989015628705399, 0.4479885272895762, 0.5516609680876238, 0.7260352445858591, 0.27378010649894813, 0.9997983871430656, 0.9994954538637708, 0.9987306693771901, 0.999568589460893, 0.9994127562413292, 0.9988581759037674, 0.702390539563224, 0.2975211574039216, 0.06778505377339213, 0.7549318274533785, 0.13828150969771993, 0.03912165960635774, 0.39367417141897243, 0.23291434050892393, 0.22812486368129295, 0.09329067907733385, 0.011244858638785778, 0.04081467209633356, 0.9996065459159867, 0.6423996239484661, 0.35727597099684083, 0.999605821711467, 0.9981901657620997, 0.9981031812570514, 0.9987374476967141, 0.9991204025078027, 0.9980161327126493, 0.9998860711808063, 0.9994229238677482, 0.7791639913306762, 0.2206923369614027, 0.8023474440167506, 0.19723083887670448, 0.9996709247703875, 0.997503892140892, 0.9993724048657553, 0.9984286690425287, 0.06669410144655241, 0.6353779623406125, 0.14162204257786437, 0.03869904651836992, 0.11746944616923635, 0.9997424712051959, 0.9982452611247198, 0.9997353605008865, 0.999532581134386, 0.08537565626502922, 0.7139822581455983, 0.17956590830963373, 0.021155029870980693, 0.9995190240870117, 0.9995912817693233, 0.9991946907623191, 0.9993862300708471, 0.9996377777539814, 0.9992957204254226, 0.9998523317979433, 0.9999085969079456, 0.9993917873353487, 0.9991987448790622, 0.9993268576231799, 0.9996009177331896, 0.9999659891442843, 0.9995754962134173, 0.9984735720719841, 0.999512078324432, 0.9993407239515165, 0.34542863012516295, 0.6544253344168126, 0.9993845965408669, 0.9990466178233537, 0.9999140468765948, 0.999243301875573, 0.38928991862811146, 0.2247820717573263, 0.38521121168090194, 0.9488766078307292, 0.05047215999099624, 0.9983058943091091, 0.9997519498360354, 0.9987796142056955, 0.49724688141948303, 0.17327739426978261, 0.32952324978655245, 0.9991741966197234, 0.9995893943317099, 0.9990974392376022, 0.9995390587198877, 0.9995072061365224, 0.9981769758286407, 0.9972309900340134, 0.999662001562329, 0.9989896274025446, 0.9987230631044067, 0.37104660584057614, 0.6287022670823681, 0.9993183803216706, 0.9492218441807193, 0.05048671445849921, 0.9990932508484281, 0.31217852753170644, 0.4364771339067162, 0.1181886902398326, 0.13308161081932685, 0.9996433177365391, 0.9963545303292906, 0.9980563069063342, 0.540417197051619, 0.45942891866670627, 0.439411074977205, 0.17384956521460518, 0.15789235874563176, 0.12497012224122343, 0.10380582734553237, 0.3677833679302495, 0.6313067186124149, 0.2786448607982708, 0.7205720604082672, 0.9998753261546184, 0.9988138677392949, 0.9990141427390677, 0.9970389496989962, 0.4877175508488393, 0.07681998053663036, 0.4353590310197585, 0.8191501867242496, 0.17953976695326018, 0.9989596573029143, 0.9990108166196129, 0.17956922334705336, 0.2276970106855654, 0.4050418405001665, 0.18745570950756582, 0.9985919086834634, 0.9982268751723742, 0.9995853488666587, 0.9984883663239073, 0.9987428086589155, 0.9995763835610111, 0.9984978831226223, 0.9990651986294766, 0.5918030192390762, 0.09542449261772522, 0.12067133147174221, 0.1534066394773744, 0.038726083326924364, 0.9980953488490613, 0.9987637474483351, 0.13840958786683472, 0.3179679721265122, 0.11870804292723122, 0.06484052764932798, 0.09551508496035621, 0.11571540318956994, 0.14863444030384412, 0.9987262178342793, 0.9974977499745581, 0.9992704126994985, 0.4322640230307598, 0.08959011568564942, 0.0758919968878436, 0.24258926516114196, 0.15962727147443084, 0.9992754320266634, 0.9996954862198085, 0.9979129727221514, 0.9979328445226795, 0.9977458189751843, 0.15798403930127033, 0.2565631371656253, 0.14327074111256063, 0.060324522573709745, 0.2995995343676011, 0.06289934975673395, 0.0191272876453226, 0.998762885217301, 0.9982667608776029, 0.6482790456253575, 0.14165472542516688, 0.08537336354697016, 0.12468439111838238, 0.9996452019683911, 0.9977379081168335, 0.9993790690870795, 0.9981461774285058, 0.9999632232943219, 0.9991337208272127, 0.2656796181110485, 0.19969573046202443, 0.3084092722273769, 0.22600208214588646, 0.998795218441343, 0.9996371534932843, 0.21860260415981073, 0.365383355744457, 0.13918579705945652, 0.05432043562581399, 0.10467828628196374, 0.11772179514044187, 0.9976136806793162, 0.9983197790903541, 0.5197846004763093, 0.4798919585687269, 0.9979691862390164, 0.19495635500393774, 0.133305801687852, 0.06949207106242995, 0.12762746125084412, 0.2860801991597311, 0.08896066684645702, 0.09923575906580465, 0.9992853232499684, 0.997010058290416, 0.7568467839545033, 0.24283401564554774, 0.9995586929934172, 0.9982483263807402, 0.9987657349649011, 0.9977626036896752, 0.23932477855714904, 0.1946584660522072, 0.12573683786460085, 0.2129455298024473, 0.045855715025282635, 0.10199126611922521, 0.018626893041766037, 0.026464206077583218, 0.03440771576700226, 0.9974109289752443, 0.9993592787599794, 0.9993145497513205, 0.9991003238937762, 0.9982913772970807, 0.9977217792454381, 0.14949601386517405, 0.28161573754161046, 0.11881787394574755, 0.16552414360823378, 0.11345519128405093, 0.06629953480633871, 0.016537434800315845, 0.043260970745753774, 0.04499859976462754, 0.9997473072388764, 0.9998967684650142, 0.1788333032241883, 0.8205292736168639, 0.9995778524584381, 0.08797045418232603, 0.5511871113154191, 0.33064146561888336, 0.029913494480509253, 0.22943574486740995, 0.702605404209909, 0.06750066117113655, 0.49852697960339293, 0.24794596317551082, 0.1508254290166822, 0.021080426018970554, 0.08156117209720751, 0.9995543516084605, 0.9988505622815786, 0.9981841148558366, 0.08102580548263086, 0.1824922118938345, 0.27217304659847363, 0.06334744792278413, 0.1491611419112068, 0.2517324456699009, 0.374945483059734, 0.624249603722143, 0.8132647929880512, 0.1864446712476123, 0.9988601115274842, 0.15791892582065087, 0.8416309513650735, 0.9985072561588664, 0.0019043609467448187, 0.7055657307689553, 0.047989895857969436, 0.14416012366858277, 0.10035982189345195, 0.9995605703532885, 0.9977277952824197, 0.9989021030780557, 0.9996952642423247, 0.9990212606815888, 0.9990479280154708, 0.9992090504967435, 0.9968298078769156, 0.9995008917427876, 0.9995435550024478, 0.9983634331936041, 0.999766729119993, 0.9988645414275478, 0.09968205611475034, 0.48980263784517997, 0.308764474650703, 0.10162571737604074, 0.3038307702821335, 0.14670625017121913, 0.4681842940246732, 0.05676894028364566, 0.02466365944907452, 0.5583649441632411, 0.1766444495679089, 0.2648350465951063, 0.9986361987843664, 0.9996331976131724, 0.7116013719399175, 0.28820133750185867, 0.9984230863848739, 0.9994093843047124, 0.21215329659328816, 0.020287505189893418, 0.20128251736184355, 0.18840375980102383, 0.20592163970902055, 0.04611426094358026, 0.02804245597920421, 0.06619404423733143, 0.018141045596423464, 0.01357116388129389, 0.09666500163115559, 0.2430097514873824, 0.2194329218212469, 0.06567831121280605, 0.07443541937451353, 0.09346528903360862, 0.2073076951358058, 0.10381336532518803, 0.31582657620057203, 0.2198113979420648, 0.3604224584881528, 0.3111077771370943, 0.23066250058385585, 0.1627353260331688, 0.18645383509063468, 0.05349841487406196, 0.011727485033969249, 0.043813357008930055, 0.9986217304600473, 0.9993440692815889, 0.9992922096416776, 0.9973450160449104, 0.9994086665675423, 0.2934133655513225, 0.2565517139414819, 0.15551850095246625, 0.1498681747932936, 0.08314051348496898, 0.061480929874807154, 0.9992651450473619, 0.9995488225107527, 0.999404917239351, 0.996838052147603, 0.9991591406701824, 0.9990953592614762, 0.9983305095265605, 0.9981924582716848, 0.9032000010253296, 0.096561842992076, 0.19140641269318837, 0.808433768778685, 0.9977912764780783, 0.9995887274415074, 0.9988383092263217, 0.9978858137617066, 0.9989409195502584, 0.5554931179293134, 0.4443606640683028, 0.2575359880838175, 0.06450000422279394, 0.17702699000716465, 0.5009190975432091, 0.9983931238909448, 0.9987485300999162, 0.266189608296051, 0.18203067153174396, 0.17517427253017903, 0.10378705939623807, 0.05982544226855692, 0.08523445033317997, 0.12610396595035145, 0.0016132703533094, 0.9981879881522531, 0.9972012885077262, 0.32134055814597995, 0.3783491488602501, 0.2209883572631822, 0.07921418410110202, 0.9984627701541386, 0.5131920329075864, 0.08137031749079378, 0.2242342336960042, 0.142366998235801, 0.038635372121582995, 0.2391282918794767, 0.7601818853707749, 0.9995036194106596, 0.9978039038358057, 0.9982516163690058, 0.9995107641762508, 0.9991194729999995, 0.9978914361210168, 0.14956862399448848, 0.8495904832339992, 0.9984795411725895, 0.999076236204327, 0.9988065879322424, 0.9985020075361063, 0.8456200479133936, 0.15418440284717597, 0.998752365398718, 0.9737785174037485, 0.026078235751542413, 0.4055359651984001, 0.4107077079383973, 0.04458398913790678, 0.13892371015371752, 0.17948254197999006, 0.46611306699544836, 0.1195260893789158, 0.12397447134609228, 0.03229912123993356, 0.07852361211624566, 0.4164487455650193, 0.038896932090413054, 0.20725678740712625, 0.2738266612335048, 0.06366711770022833, 0.3705593575398657, 0.6293693124135612, 0.9988219986021407, 0.9981151562261046, 0.9997851977422266, 0.999804745028335, 0.9996659957566143, 0.9986464393742205, 0.4442977994821098, 0.29753879784322285, 0.25804885121827775, 0.9742715808053269, 0.025378103439020586, 0.28783396875551326, 0.25433310303337514, 0.45773121634635655, 0.9991179528872509, 0.9985469799216008, 0.998903007049612, 0.9995862648743685, 0.9993943131429126, 0.9995212259948097, 0.9991705663601939, 0.9991982487410339, 0.9995404152926631, 0.9995705558720929, 0.9982066399160198, 0.13226698596325112, 0.07278843567160045, 0.45336797075453994, 0.34106581286121357, 0.9975633126847346, 0.9991847717456301, 0.9455070751451502, 0.05440086595434503, 0.9988631245608354, 0.9987427358487584, 0.3105462772479813, 0.4132620754107616, 0.21241016435360516, 0.027478111610425307, 0.03620132164548096, 0.07918729759504652, 0.5254271918294275, 0.20918283850130456, 0.015000872404161817, 0.06198677803546674, 0.08946433758347469, 0.01976076460932855, 0.29846991816392615, 0.7013282966704139, 0.9994652286933249, 0.9988904924940658, 0.13691384624466507, 0.8627183064546189, 0.9989336430115187, 0.17003030403931033, 0.44863417571818026, 0.3120636503854009, 0.01690060250993145, 0.052238225939788115, 0.803413227280393, 0.1963699740785782, 0.997445578007617, 0.9989262855767305, 0.10593470046233279, 0.4821339017508291, 0.08646966716183348, 0.32529065265642115, 0.9984887754520542, 0.9993830783865384, 0.9998271925455865, 0.7663302242238459, 0.23361342294578977, 0.9997201538858026, 0.9991778269750294, 0.9994530512457087, 0.9982950923175828, 0.8166576340920797, 0.18321566349374455, 0.49577053109817026, 0.5036757559676172, 0.998825383569318, 0.9984057219832244, 0.9997186411803173, 0.9475565855562521, 0.05177455758026356, 0.998889878165087, 0.9993566210194547, 0.9993994575515469, 0.9993871872881213, 0.9984174100369428, 0.9973101910971391, 0.9985367593549257, 0.9983726869529904, 0.9988180838192643, 0.9997615559454495, 0.2663099426492747, 0.10546345073942516, 0.5261388911190317, 0.10133918171609568, 0.998834153815182, 0.22497477417254874, 0.14833918499404142, 0.07360051633975456, 0.4351535682561778, 0.03357549327870247, 0.08422327127538924, 0.9987173134336773, 0.9993009490502328, 0.19253399884657435, 0.2655554236059707, 0.09045560575731446, 0.3942904267717576, 0.029183302974776032, 0.02779362188073908, 0.9998368408433728, 0.9988419585010475, 0.7782702311347824, 0.22163861398533588, 0.9991219088542317, 0.9988347264943921, 0.0817890088778335, 0.3279204187718745, 0.5897216855069957, 0.9997493805171337, 0.9989577489722977, 0.9995159566254929, 0.9987007920614924, 0.9992769475722566, 0.997670533897365, 0.9993366100182234, 0.9980949242340349, 0.9987745379341711, 0.9984804071228416, 0.9985276187809963, 0.9999005439006978, 0.9986366604733427, 0.4322338652759953, 0.5676994987459159, 0.2101883964240835, 0.06529975766099086, 0.3306472434975349, 0.032880348563416574, 0.06821904094465868, 0.01736205321339286, 0.12414636280018967, 0.15134179128488467, 0.9982834152779804, 0.8933785454363676, 0.10650473639711991, 0.8111699543786925, 0.1874114947105964, 0.9992130815379145, 0.9998437439444908, 0.9981902970874933, 0.9993930131563438, 0.3722931450279764, 0.6269790413128055, 0.9984027854300537, 0.9986785112118423, 0.2824406994539724, 0.47606743894892517, 0.24131552861844482, 0.999395022097676, 0.38813287435974325, 0.6118292731312839, 0.9972245890568493, 0.9985363584923704, 0.46033782375011933, 0.19604034388984806, 0.10391256490519371, 0.1397830446779303, 0.07006356300933798, 0.029806046142094058, 0.12105343500557757, 0.50019790837692, 0.13405389193399347, 0.13320140295508096, 0.1112498117480836, 0.9997288220499705, 0.9968444533272292, 0.998042616199682, 0.9235738565130859, 0.07632204657328506, 0.8282500005657595, 0.14029935757247095, 0.03128514410236708, 0.1682678978572988, 0.11433269278339356, 0.22158172960085948, 0.19250145774073546, 0.20828434033148652, 0.015037234594337631, 0.011184719946201543, 0.05704207172562788, 0.011681818610477169, 0.07065711103704496, 0.37854097285253335, 0.13068952912439458, 0.389920425410677, 0.03013232590651301, 0.9994630478784315, 0.7246561117103447, 0.26001558525045854, 0.015106539283917484, 0.9979679893336867, 0.9990301287748437, 0.9973231125121235, 0.9990215209107668, 0.9988366800627584, 0.9981579632082508, 0.9998280304023058, 0.9985716907523241, 0.9979735516436007, 0.9980939410323986, 0.9982306980848589, 0.25336596155655444, 0.7465700024063545, 0.4509886945912665, 0.0787440577857767, 0.20902968066769814, 0.11310510118320653, 0.13458075330660016, 0.013362627987889378, 0.9995164508316142, 0.9987845913500609, 0.432845586169826, 0.5670612718038806, 0.9978279286730927, 0.6568305955262731, 0.3417786822590472, 0.9980700710831897, 0.9993950130866304, 0.048838813732355615, 0.9509885389479159, 0.22837350121066277, 0.7710765815784371, 0.2618294452031437, 0.22644708774325945, 0.13553242010057373, 0.12233899867485415, 0.026626723240997668, 0.08467777751416376, 0.07448286095792592, 0.03826092213458674, 0.02962522811047939, 0.9993509349151073, 0.2179044173404452, 0.7817386291158417, 0.11974227415660439, 0.1374887890472088, 0.27871368649243955, 0.32653587398712086, 0.1374887890472088, 0.9996630911332683, 0.9993949013073374, 0.9974972378198674, 0.4770699157155544, 0.07182721973832429, 0.2240552000325447, 0.15870576668971917, 0.06820728028201616, 0.11599104623497518, 0.10795614249933747, 0.12938255246103803, 0.04388293578694443, 0.5826335324200885, 0.02019027092544861, 0.11069135753521415, 0.4595452757973673, 0.3176118851889813, 0.07073492948020804, 0.04134702299891584, 0.9982894798208772, 0.9982448610460487, 0.9997510985353241], \"Term\": [\"addictive\", \"adult\", \"afternoon\", \"allergy\", \"almond\", \"alternative\", \"alternative\", \"alternative\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazon\", \"amount\", \"amount\", \"amount\", \"amount\", \"amount\", \"amount\", \"amount\", \"antioxidant\", \"apple\", \"area\", \"area\", \"aroma\", \"aroma\", \"artificial\", \"artificial\", \"asian\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"awesome\", \"baby\", \"bag\", \"bag\", \"bag\", \"baked\", \"baking\", \"balance\", \"ball\", \"banana\", \"bar\", \"base\", \"bean\", \"beautiful\", \"beef\", \"beer\", \"berry\", \"beverage\", \"bill\", \"birthday\", \"biscuit\", \"bitter\", \"bitter\", \"black\", \"black\", \"blend\", \"blood\", \"blueberry\", \"bold\", \"bone\", \"bonus\", \"bottle\", \"bottle\", \"box\", \"box\", \"box\", \"box\", \"brand\", \"brand\", \"brand\", \"brand\", \"brand\", \"brand\", \"bread\", \"breakfast\", \"breakfast\", \"brew\", \"brewer\", \"brewing\", \"brownie\", \"bulk\", \"business\", \"butter\", \"cake\", \"calorie\", \"calorie\", \"can\", \"can\", \"candy\", \"cappuccino\", \"carb\", \"carrot\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cat\", \"celiac\", \"cereal\", \"chai\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheese\", \"cherry\", \"chew\", \"chewy\", \"chicken\", \"chili\", \"chip\", \"chocolate\", \"cinnamon\", \"coat\", \"cocoa\", \"coconut\", \"coffee\", \"combination\", \"comparable\", \"complaint\", \"condition\", \"container\", \"container\", \"convenience\", \"cook\", \"cookie\", \"cooking\", \"corn\", \"corn\", \"corn\", \"cost\", \"cost\", \"costco\", \"cracker\", \"craving\", \"cream\", \"cream\", \"cream\", \"creamer\", \"creamy\", \"crisp\", \"crunch\", \"crunchy\", \"crust\", \"cube\", \"cup\", \"customer\", \"dairy\", \"dark\", \"dark\", \"date\", \"deal\", \"deal\", \"decaf\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delivery\", \"dental\", \"diabetic\", \"diet\", \"diet\", \"different\", \"different\", \"different\", \"different\", \"different\", \"dinner\", \"dinner\", \"dish\", \"dish\", \"dog\", \"dollar\", \"door\", \"dressing\", \"drink\", \"drink\", \"drink\", \"drinker\", \"drinker\", \"drinking\", \"earth\", \"easy\", \"easy\", \"easy\", \"easy\", \"eater\", \"egg\", \"energy\", \"enjoy\", \"enjoyable\", \"espresso\", \"evening\", \"everyday\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"expiration\", \"fabulous\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"fancy\", \"farm\", \"fast\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"feed\", \"fiber\", \"filler\", \"find\", \"finger\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fish\", \"flake\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flavorful\", \"flavour\", \"flour\", \"flower\", \"food\", \"formula\", \"free\", \"free\", \"free\", \"free\", \"freezer\", \"french\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"freshness\", \"fridge\", \"fruit\", \"fruit\", \"fuel\", \"full\", \"full\", \"full\", \"full\", \"full\", \"full\", \"full\", \"garlic\", \"german\", \"gift\", \"gift\", \"ginger\", \"girl\", \"glutenfree\", \"golden\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"goodness\", \"grain\", \"gram\", \"granola\", \"grape\", \"greasy\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"green\", \"grocery\", \"ground\", \"ground\", \"hair\", \"happy\", \"happy\", \"happy\", \"happy\", \"health\", \"health\", \"health\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"heat\", \"heavy\", \"herb\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"homemade\", \"homemade\", \"honey\", \"honey\", \"hooked\", \"hour\", \"hour\", \"iced\", \"ingredient\", \"ingredient\", \"ingredient\", \"ingredient\", \"ingredient\", \"instant\", \"interesting\", \"italian\", \"item\", \"jar\", \"jelly\", \"jerky\", \"joe\", \"juice\", \"kcup\", \"kettle\", \"keurig\", \"kick\", \"kid\", \"kid\", \"kid\", \"kid\", \"large\", \"large\", \"large\", \"large\", \"large\", \"last\", \"last\", \"last\", \"latte\", \"lemon\", \"light\", \"light\", \"lime\", \"liquid\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"long\", \"long\", \"long\", \"long\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lovely\", \"lunch\", \"machine\", \"magic\", \"maker\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"maple\", \"meal\", \"meat\", \"medicine\", \"medium\", \"member\", \"memory\", \"mess\", \"mild\", \"mild\", \"milk\", \"milk\", \"mini\", \"minute\", \"mix\", \"mocha\", \"moist\", \"month\", \"month\", \"morning\", \"morning\", \"morning\", \"morning\", \"mother\", \"movie\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"muffin\", \"mustard\", \"natural\", \"natural\", \"natural\", \"natural\", \"newman\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"noodle\", \"nut\", \"nutritious\", \"nuts\", \"oatmeal\", \"oats\", \"office\", \"office\", \"old\", \"olive\", \"onion\", \"online\", \"open\", \"open\", \"orange\", \"order\", \"order\", \"organic\", \"organic\", \"organic\", \"organic\", \"pack\", \"pack\", \"pack\", \"pack\", \"pack\", \"pack\", \"package\", \"package\", \"package\", \"package\", \"package\", \"packet\", \"packet\", \"pancake\", \"pantry\", \"pasta\", \"peanut\", \"pepper\", \"peppermint\", \"perfect\", \"perfect\", \"perfect\", \"picky\", \"picky\", \"piece\", \"piece\", \"piece\", \"pill\", \"pizza\", \"plant\", \"plastic\", \"pleasant\", \"pleased\", \"pocket\", \"pod\", \"popcorn\", \"potato\", \"pour\", \"powder\", \"powder\", \"powder\", \"powder\", \"preference\", \"pretzel\", \"price\", \"price\", \"pricey\", \"prime\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"protein\", \"protein\", \"pumpkin\", \"puppy\", \"purchase\", \"purchase\", \"purse\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"quick\", \"quick\", \"raisin\", \"reasonable\", \"recipe\", \"recipe\", \"recipe\", \"recipe\", \"refreshing\", \"restaurant\", \"rice\", \"rich\", \"rich\", \"roast\", \"room\", \"salad\", \"salmon\", \"salt\", \"salt\", \"salty\", \"salty\", \"sandwich\", \"satisfied\", \"sauce\", \"save\", \"save\", \"season\", \"seed\", \"seller\", \"service\", \"shake\", \"shampoo\", \"share\", \"ship\", \"shipment\", \"shipping\", \"single\", \"single\", \"single\", \"single\", \"sister\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"skeptical\", \"skin\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"smooth\", \"smoothie\", \"snack\", \"snack\", \"soda\", \"sodium\", \"soft\", \"soft\", \"soft\", \"soup\", \"sour\", \"spicy\", \"splenda\", \"spoon\", \"staple\", \"starbuck\", \"start\", \"stash\", \"steep\", \"stevia\", \"store\", \"strawberry\", \"strong\", \"strong\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"style\", \"subscribe\", \"subscribe\", \"substitute\", \"substitute\", \"subtle\", \"sugar\", \"sugary\", \"summer\", \"supermarket\", \"supermarket\", \"supply\", \"surprise\", \"sweet\", \"sweet\", \"sweet\", \"sweetener\", \"syrup\", \"syrup\", \"tangy\", \"tart\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tea\", \"temperature\", \"terrific\", \"texture\", \"texture\", \"thank\", \"thank\", \"thank\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tomato\", \"tooth\", \"tooth\", \"tooth\", \"tortilla\", \"touch\", \"town\", \"traditional\", \"training\", \"travel\", \"treat\", \"tree\", \"trick\", \"tuna\", \"unique\", \"vanilla\", \"vanilla\", \"variety\", \"variety\", \"variety\", \"variety\", \"variety\", \"variety\", \"vegetable\", \"vegetarian\", \"veggie\", \"veggie\", \"vendor\", \"vinegar\", \"vinegar\", \"waffle\", \"warm\", \"water\", \"water\", \"weak\", \"weak\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wellness\", \"wheat\", \"wheat\", \"whole\", \"whole\", \"whole\", \"whole\", \"whole\", \"wife\", \"wine\", \"winter\", \"wonderful\", \"wonderful\", \"wonderful\", \"wonderful\", \"wonderful\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yogurt\", \"young\", \"yummy\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 5, 10, 7, 1, 9, 8, 4, 3, 6]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el168015918847566884177429128\", ldavis_el168015918847566884177429128_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el168015918847566884177429128\", ldavis_el168015918847566884177429128_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el168015918847566884177429128\", ldavis_el168015918847566884177429128_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.114133 -0.089422       1        1  16.613831\n",
       "4     -0.178076  0.154759       2        1  16.040416\n",
       "9     -0.124866  0.084790       3        1  15.597185\n",
       "6     -0.076881 -0.046007       4        1  11.083436\n",
       "0     -0.069788  0.187922       5        1  10.135822\n",
       "8     -0.074469 -0.047118       6        1   8.277793\n",
       "7      0.096319 -0.251816       7        1   6.881308\n",
       "3      0.051990 -0.198989       8        1   5.825599\n",
       "2      0.075221  0.049388       9        1   5.445477\n",
       "5      0.414682  0.156492      10        1   4.099131, topic_info=          Term          Freq         Total Category  logprob  loglift\n",
       "19      coffee  30798.000000  30798.000000  Default  30.0000  30.0000\n",
       "44        food  22329.000000  22329.000000  Default  29.0000  29.0000\n",
       "160     flavor  32586.000000  32586.000000  Default  28.0000  28.0000\n",
       "79       store  13896.000000  13896.000000  Default  27.0000  27.0000\n",
       "200      sugar   8893.000000   8893.000000  Default  26.0000  26.0000\n",
       "...        ...           ...           ...      ...      ...      ...\n",
       "440      local   1231.086829   5938.033314  Topic10  -4.1990   1.6209\n",
       "1477  homemade    631.240872   1010.813617  Topic10  -4.8669   2.7236\n",
       "709     recipe    869.186576   2671.457027  Topic10  -4.5471   2.0716\n",
       "622      fresh    713.241995   6056.652459  Topic10  -4.7448   1.0553\n",
       "705     family    596.123257   4009.837819  Topic10  -4.9242   1.2883\n",
       "\n",
       "[531 rows x 6 columns], token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "2863      9  0.999216  addictive\n",
       "5776      7  0.998600      adult\n",
       "673       5  0.998844  afternoon\n",
       "2502      1  0.999601    allergy\n",
       "386       7  0.999476     almond\n",
       "...     ...       ...        ...\n",
       "26        4  0.070735       year\n",
       "26        6  0.041347       year\n",
       "6308     10  0.998289     yogurt\n",
       "1647      9  0.998245      young\n",
       "1830      9  0.999751      yummy\n",
       "\n",
       "[768 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 5, 10, 7, 1, 9, 8, 4, 3, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "#https://github.com/bmabey/pyLDAvis\n",
    "#https://speakerdeck.com/bmabey/visualizing-topic-models\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13bd9af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.844296513043854\n",
      "\n",
      "Coherence Score:  0.4332053140362627\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerplexity: ', lda_model.log_perplexity(doc_term_matrix,total_docs=10000))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=tokenized_reviews, dictionary=dictionary , coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39192ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86055bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=doc_term_matrix, texts=tokenized_reviews, start=2, limit=50, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=50; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()# Print the coherence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[7]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "optimal_model.print_topics(num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(optimal_model, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
